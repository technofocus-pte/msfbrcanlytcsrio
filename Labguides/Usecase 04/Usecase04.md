# ì‚¬ìš© ì‚¬ë¡€ 04: Apache Sparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„

**ì†Œê°œ**

Apache SparkëŠ” ë¶„ì‚° ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ì—”ì§„ìœ¼ë¡œ, ë°ì´í„° ë ˆì´í¬
ìŠ¤í† ë¦¬ì§€ì—ì„œ ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ íƒìƒ‰, ì²˜ë¦¬ ë° ë¶„ì„í•˜ëŠ” ë° ë„ë¦¬
ì‚¬ìš©ë©ë‹ˆë‹¤. SparkëŠ” Azure HDInsight, Azure Databricks, Azure Synapse
Analytics ë° Microsoft Fabricì„ ë¹„ë¡¯í•œ ë§ì€ ë°ì´í„° í”Œë«í¼ ì œí’ˆì—ì„œ ì²˜ë¦¬
ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Sparkì˜ ì´ì  ì¤‘ í•˜ë‚˜ëŠ” Java, Scala, Python
ë° SQLì„ í¬í•¨í•œ ê´‘ë²”ìœ„í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ì§€ì›í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. SparkëŠ”
ë°ì´í„° ì •ë¦¬ ë° ì¡°ì‘, í†µê³„ ë¶„ì„ ë° ê¸°ê³„ í•™ìŠµ, ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”ë¥¼
í¬í•¨í•œ ë°ì´í„° ì²˜ë¦¬ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ë§¤ìš° ìœ ì—°í•œ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

Microsoft Fabric Lakehouseì˜ í…Œì´ë¸”ì€ Apache Sparkìš© ì˜¤í”ˆ ì†ŒìŠ¤ *Delta
Lake* í˜•ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. Delta LakeëŠ” ì¼ê´„ ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°
ì‘ì—… ëª¨ë‘ì— ëŒ€í•œ ê´€ê³„í˜• ì˜ë¯¸ ì²´ê³„ì— ëŒ€í•œ ì§€ì›ì„ ì¶”ê°€í•˜ê³ , Apache Sparkë¥¼
ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë ˆì´í¬ì˜ ê¸°ë³¸ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼
ì²˜ë¦¬í•˜ê³  ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” Lakehouse ì•„í‚¤í…ì²˜ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Microsoft Fabricì—ì„œ Dataflow (Gen2)ì€ ë‹¤ì–‘í•œ ë°ì´í„° ì›ë³¸ì— ì—°ê²°í•˜ê³ 
Power Query Onlineì—ì„œ ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë°ì´í„°
íŒŒì´í”„ë¼ì¸ì—ì„œ ë°ì´í„°ë¥¼ Lakehouse ë˜ëŠ” ê¸°íƒ€ ë¶„ì„ ì €ì¥ì†Œë¡œ ìˆ˜ì§‘í•˜ê±°ë‚˜
Power BI ë³´ê³ ì„œì— ëŒ€í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì •ì˜í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ë©ì€ Dataflow (Gen2)ì˜ ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ì†Œê°œí•˜ê³  ì—”í„°í”„ë¼ì´ì¦ˆì— ì¡´ì¬í• 
ìˆ˜ ìˆëŠ” ë³µì¡í•œ ì†”ë£¨ì…˜ì„ ë§Œë“¤ì§€ ì•Šë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

**ëª©í‘œ**:

- Fabric í‰ê°€íŒì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ëœ Microsoft Fabricì—ì„œ ì‘ì—… ì˜ì—­ì„
  ë§Œë“­ë‹ˆë‹¤.

- Lakehouse í™˜ê²½ì„ ì„¤ì •í•˜ê³  ë¶„ì„ì„ ìœ„í•´ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.

- ëŒ€í™”í˜• ë°ì´í„° íƒìƒ‰ ë° ë¶„ì„ì„ ìœ„í•œ Notebookì„ ìƒì„±í•©ë‹ˆë‹¤.

- ì¶”ê°€ ì²˜ë¦¬ ë° ì‹œê°í™”ë¥¼ ìœ„í•´ ë°ì´í„°ë¥¼ ë°ì´í„° í”„ë ˆì„ì— ë¡œë“œí•©ë‹ˆë‹¤.

- PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì— ë³€í™˜ì„ ì ìš©í•©ë‹ˆë‹¤.

- ìµœì í™”ëœ ì¿¼ë¦¬ë¥¼ ìœ„í•´ ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë¶„í• í•©ë‹ˆë‹¤.

- êµ¬ì¡°í™”ëœ ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•´ Spark ë©”íƒ€ìŠ¤í† ì–´ì— í…Œì´ë¸” ë§Œë“¤ê¸°

- DataFrameì„ "salesorders"ë¼ëŠ” ê´€ë¦¬ë˜ëŠ” Delta tableë¡œ ì €ì¥í•©ë‹ˆë‹¤.

- DataFrameì„ ì§€ì •ëœ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ "external_salesorder"ì´ë¼ëŠ” ì™¸ë¶€
  Delta tableë¡œ ì €ì¥í•©ë‹ˆë‹¤.

- ê´€ë¦¬ í…Œì´ë¸”ê³¼ ì™¸ë¶€ í…Œì´ë¸”ì˜ ì†ì„±ì„ ì„¤ëª…í•˜ê³  ë¹„êµí•©ë‹ˆë‹¤.

- ë¶„ì„ ë° ë³´ê³ ë¥¼ ìœ„í•´ í…Œì´ë¸”ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

- matplotlib ë° seabornê³¼ ê°™ì€ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼
  ì‹œê°í™”í•©ë‹ˆë‹¤.

- ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ í™˜ê²½ì—ì„œ Data Lakehouseë¥¼ ì„¤ì •í•˜ê³  í›„ì† ë¶„ì„ì„ ìœ„í•´
  ê´€ë ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

- ë°ì´í„°ë¥¼ ì¶”ì¶œ, ë³€í™˜ ë° Lakehouseì— ë¡œë“œí•˜ê¸° ìœ„í•œ Dataflowì„
  ì •ì˜í•©ë‹ˆë‹¤.

- Power Query ë‚´ì—ì„œ ë°ì´í„° ëŒ€ìƒì„ êµ¬ì„±í•˜ì—¬ ë³€í™˜ëœ ë°ì´í„°ë¥¼ Lakehouseì—
  ì €ì¥í•©ë‹ˆë‹¤.

- Dataflowì„ íŒŒì´í”„ë¼ì¸ì— í†µí•©í•˜ì—¬ ì˜ˆì•½ëœ ë°ì´í„° ì²˜ë¦¬ ë° ìˆ˜ì§‘ì„
  í™œì„±í™”í•©ë‹ˆë‹¤.

- ì‘ì—…ê³µê°„ ë° ì—°ê´€ëœ ìš”ì†Œë¥¼ ì œê±°í•˜ì—¬ ì—°ìŠµì„ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.

# ì—°ìŠµ 1: ì‘ì—… ì˜ì—­, Lakehouse, Notebook ë§Œë“¤ê¸° ë° ë°ì´í„° í”„ë ˆì„ì— ë°ì´í„° ë¡œë“œ 

## íƒœìŠ¤í¬ 1: ì‘ì—…ê³µê°„ ì‘ì„± 

Fabricì—ì„œ ë°ì´í„°ë¡œ ì‘ì—…í•˜ê¸° ì „ì— Fabric í‰ê°€íŒì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ëœ ì‘ì—…
ì˜ì—­ì„ ìƒì„±í•˜ì„¸ìš”.

1.  ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ì£¼ì†Œ í‘œì‹œì¤„ë¡œ ì´ë™í•œ ë‹¤ìŒ
    +++https://app.fabric.microsoft.com/+++ URLì„ ì…ë ¥í•˜ê±°ë‚˜ ë¶™ì—¬ë„£ì€ í›„
    **Enter** ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.

> **ì°¸ê³ **: Microsoft Fabric í™ˆ í˜ì´ì§€ë¡œ ì´ë™í•˜ë©´ \#2ì—ì„œ \#4ê¹Œì§€ì˜
> ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ì„¸ìš”.
>
> ![](./media/image1.png)

2.  **Microsoft Fabric** ì°½ì—ì„œ ìê²© ì¦ëª…ì„ ì…ë ¥í•˜ê³  **Submit** ë²„íŠ¼ì„
    í´ë¦­í•˜ì„¸ìš”.

> ![](./media/image2.png)

3.  **Microsoft** ì°½ì—ì„œ ì•”í˜¸ë¥¼ ì…ë ¥í•˜ê³  **Sign in** ë²„íŠ¼ì„
    í´ë¦­í•˜ì„¸ìš”**.**

> ![A login screen with a red box and blue text Description
> automatically generated](./media/image3.png)

4.  **Stay signed in?** ì°½ì—ì„œ **Yes** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

> ![A screenshot of a computer error Description automatically
> generated](./media/image4.png)

5.  Fabric home pageì—ì„œ **+New workspace**Â íƒ€ì¼ì„ ì„ íƒí•˜ì„¸ìš”.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image5.png)

6.  **Create a workspace tab**ì—ì„œ ë‹¤ìŒ ì„¸ë¶€ ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  **Apply**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

[TABLE]

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image6.png)
>
> ![](./media/image7.png)

7.  ë°°í¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì„¸ìš”. ì™„ë£Œí•˜ëŠ” ë° 2-3ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤. ìƒˆ
    ì‘ì—… ì˜ì—­ì´ ì—´ë¦¬ë©´ ë¹„ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image8.png)

## ì‘ì—… 2: Lakehouse ìƒì„±í•˜ê³  íŒŒì¼ ì—…ë¡œë“œ

ì´ì œ ì‘ì—… ì˜ì—­ì´ ìˆìœ¼ë¯€ë¡œ í¬í„¸ì—ì„œ *ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§* í™˜ê²½ìœ¼ë¡œ ì „í™˜
í•˜ê³  ë¶„ì„í•  ë°ì´í„° íŒŒì¼ì— ëŒ€í•œ Data Lakehouseë¥¼ ë§Œë“¤ ì°¨ë¡€ì…ë‹ˆë‹¤.

1.  íƒìƒ‰ ëª¨ìŒì—ì„œ **+** **New item** ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒˆ Eventhouseë¥¼
    ìƒì„±í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image9.png)

2.  "**Lakehouse**" íƒ€ì¼ì„ í´ë¦­í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image10.png)

3.  **New lakehouse**Â ëŒ€í™” ìƒìì—ì„œ **Name**Â í•„ë“œì—
    **+++Fabric_lakehouse+++**Â ë¥¼ ì…ë ¥í•˜ê³  ìƒˆ lakehouseë¥¼
    ì—´ë ¤ë©´Â **Create**Â ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image11.png)

4.  1ë¶„ ì •ë„ í›„ì— ë¹ˆ ìƒˆ lakehouseê°€ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤. ë¶„ì„ì„ ìœ„í•´ ì¼ë¶€
    ë°ì´í„°ë¥¼ ë°ì´í„° lakehouseë¡œ ìˆ˜ì§‘í•´ì•¼ í•©ë‹ˆë‹¤.

![](./media/image12.png)

5.  **Successfully created SQL endpoint**ë¼ëŠ” ì•Œë¦¼ì´ í‘œì‹œë©ë‹ˆë‹¤.

![](./media/image13.png)

6.  **Explorer** ì„¹ì…˜ì˜, **fabric_lakehouse**ì—ì„œ **Files folder** ì˜†ì—
    ë§ˆìš°ìŠ¤ë¥¼ ë†“ì€ í›„ ê°€ë¡œ ì¤„ì„í‘œ**(...)** ë©”ë‰´ë¥¼ í´ë¦­í•˜ì„¸ìš”.
    **Upload**ë¥¼ íƒìƒ‰í•˜ì—¬ í´ë¦­í•œ í›„ ì•„ë˜ ì´ë¯¸ì§€ì™€ ê°™ì´ **Upload folder**
    í´ë”ë¥¼ í´ë¦­í•˜ì„¸ìš”.

![](./media/image14.png)

7.  ì˜¤ë¥¸ìª½ì— ë‚˜íƒ€ë‚˜ëŠ” **Upload folder** ì°½ì—ì„œ **Files/** ì•„ë˜ì˜
    **folder icon**ì„ ì„ íƒí•œ í›„ **C:\LabFiles**ë¡œ ì´ë™í•œ í›„ **orders**
    í´ë”ë¥¼ ì„ íƒí•˜ê³  **Upload** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

![](./media/image15.png)

8.  **Upload 3 files to this site?** ëŒ€í™” ìƒìê°€ ë‚˜íƒ€ë‚˜ë©´ **Upload**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

![](./media/image16.png)

9.  Upload folder ì°½ì—ì„œ **Upload** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

> ![](./media/image17.png)

10. íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ **Upload folder** ì°½ì„ ë‹«ìœ¼ì„¸ìš”.

> ![](./media/image18.png)

11. **Files**Â í™•ì¥í•˜ê³  **orders** í´ë”ë¥¼ ì„ íƒí•˜ê³  CSV íŒŒì¼ì´
    ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

> ![](./media/image19.png)

## ì‘ì—… 3: notebookë¥¼ ìƒì„±í•˜ê¸°

Apache Sparkì—ì„œ ë°ì´í„°ë¡œ ì‘ì—…í•˜ë ¤ë©´ *Notebook*ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Notebookì€ ì½”ë“œë¥¼ ì‘ì„± ë° ì‹¤í–‰í•˜ê³ (ì—¬ëŸ¬ ì–¸ì–´ë¡œ) ë©”ëª¨ë¥¼ ì¶”ê°€í•˜ì—¬ ë¬¸ì„œí™”í• 
ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.

1.  Datalakeì˜ **orders**Â í´ë” ë‚´ìš©ì„ ë³´ëŠ” ë™ì•ˆ **Home**Â  í˜ì´ì§€ì˜
    **Open notebook** ë©”ë‰´ì—ì„œ **New notebook**ì„ ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image20.png)

2.  ëª‡ ì´ˆ í›„ì— ë‹¨ì¼ *ì…€*ì´ í¬í•¨ëœ ìƒˆ ë…¸íŠ¸ë¶ì´ ì—´ë¦½ë‹ˆë‹¤. ì „ì í•„ê¸°ì¥ì€
    *ì½”ë“œ* ë˜ëŠ” *ë§ˆí¬ë‹¤ìš´*(ì„œì‹ì´ ì§€ì •ëœ í…ìŠ¤íŠ¸)ì„ í¬í•¨í•  ìˆ˜ ìˆëŠ” í•˜ë‚˜
    ì´ìƒì˜ ì…€ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

![](./media/image21.png)

3.  ì²« ë²ˆì§¸ ì…€(í˜„ì¬ ì½”ë“œ ì…€)ì„ ì„ íƒí•œ ë‹¤ìŒ ì˜¤ë¥¸ìª½ ìƒë‹¨ì˜ ë™ì  ë„êµ¬
    ëª¨ìŒì—ì„œ **Mâ†“** ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ **convert the cell to
    aÂ markdownÂ cell**.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image22.png)

4.  ì…€ì´ ë§ˆí¬ë‹¤ìš´ ì…€ë¡œ ë³€ê²½ë˜ë©´ í¬í•¨ëœ í…ìŠ¤íŠ¸ê°€ ë Œë”ë§ë©ë‹ˆë‹¤.

![](./media/image23.png)

5.  ğŸ–‰ (**Edit**) ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì…€ì„ í¸ì§‘ ëª¨ë“œë¡œ ì „í™˜í•˜ê³  ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼
    ë°”ê¾¼ ë‹¤ìŒ ë‹¤ìŒê³¼ ê°™ì´ ë§ˆí¬ë‹¤ìš´ì„ ìˆ˜ì •í•˜ì„¸ìš”.

> CodeCopy
>
> \# Sales order data exploration
>
> Use the code in this notebook to explore sales order data.

![](./media/image24.png)

![A screenshot of a computer Description automatically
generated](./media/image25.png)

6.  ì „ì í•„ê¸°ì¥ì—ì„œ ì…€ ì™¸ë¶€ì˜ ì•„ë¬´ ê³³ì´ë‚˜ í´ë¦­í•˜ì—¬ í¸ì§‘ì„ ì¤‘ì§€í•˜ê³ 
    ë Œë”ë§ëœ ë§ˆí¬ë‹¤ìš´ì„ í™•ì¸í•˜ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image26.png)

## ì‘ì—… 4: ë°ì´í„° í”„ë ˆì„ì— ë°ì´í„° ë¡œë“œ

ì´ì œ ë°ì´í„°ë¥¼ *ë°ì´í„° í”„ë ˆì„*ì— ë¡œë“œí•˜ëŠ” ì½”ë“œë¥¼ ì‹¤í–‰í•  ì¤€ë¹„ê°€
ë˜ì—ˆìŠµë‹ˆë‹¤. Sparkì˜ ë°ì´í„° í”„ë ˆì„ì€ Pythonì˜ Pandas ë°ì´í„° í”„ë ˆì„ê³¼
ìœ ì‚¬í•˜ë©° í–‰ê³¼ ì—´ì˜ ë°ì´í„° ì‘ì—…ì„ ìœ„í•œ ê³µí†µ êµ¬ì¡°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**ì°¸ê³ **: SparkëŠ” Scala, Java ë“±ì„ í¬í•¨í•œ ì—¬ëŸ¬ ì½”ë”© ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
ì´ ì—°ìŠµì—ì„œëŠ” Pythonì˜ Spark ìµœì í™” ë³€í˜•ì¸ *PySpark*ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
PySparkëŠ” Sparkì—ì„œ ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ ì¤‘ í•˜ë‚˜ì´ë©° Fabric
Notebookì˜ ê¸°ë³¸ ì–¸ì–´ì…ë‹ˆë‹¤.

1.  ë…¸íŠ¸ë¶ì´ í‘œì‹œëœ ìƒíƒœì—ì„œ **Files** ëª©ë¡ì„ í™•ì¥í•˜ê³  **orders**Â í´ë”ë¥¼
    ì„ íƒí•˜ì—¬ CSV íŒŒì¼ì´ ë…¸íŠ¸ë¶ í¸ì§‘ê¸° ì˜†ì— ë‚˜ì—´ë˜ë„ë¡ í•©ë‹ˆë‹¤.

![](./media/image27.png)

2.  ê·¸ëŸ¬ë‚˜ ì´ì œ ë§ˆìš°ìŠ¤ë¥¼ 2019.csv íŒŒì¼. 2019.csv ì˜†ì˜ ìˆ˜í‰ íƒ€ì›
    **(...)**ì„ í´ë¦­í•˜ì„¸ìš”. **Load data**ë¥¼ íƒìƒ‰í•˜ê³  í´ë¦­í•œ í›„
    **Spark**ë¥¼ ì„ íƒí•˜ì„¸ìš”. ë‹¤ìŒ ì½”ë“œê°€ í¬í•¨ëœ ìƒˆ ì½”ë“œ ì…€ì´ ë…¸íŠ¸ë¶ì—
    ì¶”ê°€ë©ë‹ˆë‹¤:

> CodeCopy
>
> df =
> spark.read.format("csv").option("header","true").load("Files/orders/2019.csv")
>
> \# df now is a Spark DataFrame containing CSV data from
> "Files/orders/2019.csv".
>
> display(df)
>
> ![](./media/image28.png)
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image29.png)

**íŒ**: Â« ì•„ì´ì½˜ì„ **ì‚¬ìš©í•˜ì—¬ ì™¼ìª½ì˜ Lakehouse íƒìƒ‰ê¸° ì°½ì„ ìˆ¨ê¸¸ ìˆ˜
ìˆìŠµë‹ˆë‹¤** . í•¨

ê·¸ë˜ì„œ ë…¸íŠ¸ë¶ì— ì§‘ì¤‘í•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.

3.  ì…€ ì™¼ìª½ì— ìˆëŠ” **â–· Run cell**ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image30.png)

**ì°¸ê³ **: Spark ì½”ë“œë¥¼ ì²˜ìŒ ì‹¤í–‰í•˜ëŠ” ê²ƒì´ë¯€ë¡œ Spark ì„¸ì…˜ì„ ì‹œì‘í•´ì•¼
í•©ë‹ˆë‹¤. ì¦‰, ì„¸ì…˜ì˜ ì²« ë²ˆì§¸ ì‹¤í–‰ì„ ì™„ë£Œí•˜ëŠ” ë° 1ë¶„ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
í›„ì† ì‹¤í–‰ì´ ë” ë¹¨ë¼ì§‘ë‹ˆë‹¤.

4.  ì…€ ëª…ë ¹ì´ ì™„ë£Œë˜ë©´ ì…€ ì•„ë˜ì˜ ì¶œë ¥ì„ ê²€í† í•˜ë©´ ë‹¤ìŒê³¼ ìœ ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤:

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image31.png)

5.  ì¶œë ¥ì—ëŠ” 2019.csv íŒŒì¼ì˜ ë°ì´í„° í–‰ê³¼ ì—´ì´ í‘œì‹œë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì—´
    ë¨¸ë¦¬ê¸€ì´ ì œëŒ€ë¡œ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë°ì´í„° í”„ë ˆì„ì— ë¡œë“œí•˜ëŠ”
    ë° ì‚¬ìš©ë˜ëŠ” ê¸°ë³¸ ì½”ë“œëŠ” CSV íŒŒì¼ì— ì²« ë²ˆì§¸ í–‰ì— ì—´ ì´ë¦„ì´ í¬í•¨ë˜ì–´
    ìˆë‹¤ê³  ê°€ì •í•˜ì§€ë§Œ, ì´ ê²½ìš° CSV íŒŒì¼ì—ëŠ” í—¤ë” ì •ë³´ê°€ ì—†ëŠ” ë°ì´í„°ë§Œ
    í¬í•¨ë©ë‹ˆë‹¤.

6.  **header**Â ë” ì˜µì…˜ì„ **false**ë¡œ ì„¤ì •í•˜ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.
    **Cell**ì˜ ëª¨ë“  ì½”ë“œë¥¼ ë‹¤ìŒ ì½”ë“œë¡œ ë°”ê¾¸ê³  **â–· Run cell** ë²„íŠ¼ì„
    í´ë¦­í•˜ê³  ì¶œë ¥ì„ ê²€í† í•˜ì„¸ìš”.

> CodeCopy
>
> df =
> spark.read.format("csv").option("header","false").load("Files/orders/2019.csv")
>
> \# df now is a Spark DataFrame containing CSV data from
> "Files/orders/2019.csv".
>
> display(df)

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image32.png)

7.  ì´ì œ ë°ì´í„° í”„ë ˆì„ì— ì²« ë²ˆì§¸ í–‰ì´ ë°ì´í„° ê°’ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ í¬í•¨ë˜ì§€ë§Œ
    ì—´ ì´ë¦„ì€ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì–´ ê·¸ë‹¤ì§€ ìœ ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼
    ì´í•´í•˜ë ¤ë©´ íŒŒì¼ì˜ ë°ì´í„° ê°’ì— ëŒ€í•œ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ë° ë°ì´í„° ìœ í˜•ì„
    ëª…ì‹œì ìœ¼ë¡œ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.

8.  **Cell**ì˜ ëª¨ë“  ì½”ë“œë¥¼ ë‹¤ìŒ ì½”ë“œë¡œ ë°”ê¾¸ê³  **â–· Run cell** ë²„íŠ¼ì„
    í´ë¦­í•˜ê³  ì¶œë ¥ì„ ê²€í† í•˜ì„¸ìš”.

> from pyspark.sql.types import \*
>
> orderSchema = StructType(\[
>
> StructField("SalesOrderNumber", StringType()),
>
> StructField("SalesOrderLineNumber", IntegerType()),
>
> StructField("OrderDate", DateType()),
>
> StructField("CustomerName", StringType()),
>
> StructField("Email", StringType()),
>
> StructField("Item", StringType()),
>
> StructField("Quantity", IntegerType()),
>
> StructField("UnitPrice", FloatType()),
>
> StructField("Tax", FloatType())
>
> \])
>
> df =
> spark.read.format("csv").schema(orderSchema).load("Files/orders/2019.csv")
>
> display(df)
>
> ![](./media/image33.png)
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image34.png)

9.  ì´ì œ ë°ì´í„° í”„ë ˆì„ì—ëŠ” ì˜¬ë°”ë¥¸ ì—´ ì´ë¦„ì´ í¬í•¨ë©ë‹ˆë‹¤(ê° í–‰ì˜ ì„œìˆ˜
    ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ëª¨ë“  ë°ì´í„° í”„ë ˆì„ì— ë‚´ì¥ëœ ì—´ì¸ **Index**
    ì™¸ì—ë„). ì—´ì˜ ë°ì´í„° í˜•ì‹ì€ ì…€ì˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ê°€ì ¸ì˜¨ Spark SQL
    ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì •ì˜ëœ í‘œì¤€ í˜•ì‹ ì§‘í•©ì„ ì‚¬ìš©í•˜ì—¬ ì§€ì •ë©ë‹ˆë‹¤.

10. ë°ì´í„° í”„ë ˆì„ì„ í™•ì¸í•˜ì—¬ ë³€ê²½ ì‚¬í•­ì´ ë°ì´í„°ì— ì ìš©ë˜ì—ˆëŠ”ì§€
    í™•ì¸í•˜ì„¸ìš”.

11. ì…€ ì¶œë ¥ ì•„ë˜ì— ìˆëŠ” + **Code**Â ì•„ì´ì½˜ì„ ì‚¬ìš©í•˜ì—¬ Notebookì— ìƒˆ ì½”ë“œ
    ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. **â–· Run cell**ë²„íŠ¼ì„ í´ë¦­í•˜ê³ 
    ì¶œë ¥ì„ ê²€í† í•˜ì„¸ìš”.

> CodeCopy
>
> display(df)
>
> ![](./media/image35.png)

12. ë°ì´í„° í”„ë ˆì„ì—ëŠ” **2019.csv** íŒŒì¼ì˜ ë°ì´í„°ë§Œ í¬í•¨ë©ë‹ˆë‹¤. íŒŒì¼
    ê²½ë¡œê°€ \* ì™€ì¼ë“œì¹´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ **orders** í´ë”ì˜ ëª¨ë“  íŒŒì¼ì—ì„œ íŒë§¤
    ì£¼ë¬¸ ë°ì´í„°ë¥¼ ì½ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”

13. ì…€ ì¶œë ¥ ì•„ë˜ì— ìˆëŠ” + **Code**Â ì•„ì´ì½˜ì„ ì‚¬ìš©í•˜ì—¬ Notebookì— ìƒˆ ì½”ë“œ
    ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.

CodeCopy

> from pyspark.sql.types import \*
>
> orderSchema = StructType(\[
>
> Â  Â  StructField("SalesOrderNumber", StringType()),
>
> Â  Â  StructField("SalesOrderLineNumber", IntegerType()),
>
> Â  Â  StructField("OrderDate", DateType()),
>
> Â  Â  StructField("CustomerName", StringType()),
>
> Â  Â  StructField("Email", StringType()),
>
> Â  Â  StructField("Item", StringType()),
>
> Â  Â  StructField("Quantity", IntegerType()),
>
> Â  Â  StructField("UnitPrice", FloatType()),
>
> Â  Â  StructField("Tax", FloatType())
>
> Â  Â  \])
>
> df =
> spark.read.format("csv").schema(orderSchema).load("Files/orders/\*.csv")
>
> display(df)
>
> ![](./media/image36.png)

14. ìˆ˜ì •ëœ ì½”ë“œ ì…€ì„ ì‹¤í–‰í•˜ê³  ì¶œë ¥ì„ ê²€í† í•˜ë©´ ì´ì œ 2019ë…„, 2020ë…„,
    2021ë…„ ë§¤ì¶œì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image37.png)

**ì°¸ê³ **: í–‰ì˜ í•˜ìœ„ ì§‘í•©ë§Œ í‘œì‹œë˜ë¯€ë¡œ ëª¨ë“  ì—°ë„ì˜ ì˜ˆë¥¼ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ì—°ìŠµ 2: ë°ì´í„° í”„ë ˆì„ì˜ ë°ì´í„° íƒìƒ‰

dataframe ê°œì²´ì—ëŠ” í¬í•¨ëœ ë°ì´í„°ë¥¼ í•„í„°ë§, ê·¸ë£¹í™” ë° ì¡°ì‘í•˜ëŠ” ë° ì‚¬ìš©í• 
ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ í•¨ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ì‘ì—… 1: ë°ì´í„° í”„ë ˆì„ í•„í„°ë§

1.  ì…€ ì¶œë ¥ ì•„ë˜ì— ìˆëŠ” + **Code**Â ì•„ì´ì½˜ì„ ì‚¬ìš©í•˜ì—¬ Notebookì— ìƒˆ ì½”ë“œ
    ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.

> customers = df\['CustomerName', 'Email'\]
>
> print(customers.count())
>
> print(customers.distinct().count())
>
> display(customers.distinct())
>
> ![](./media/image38.png)

2.  ìƒˆ ì½”ë“œ ì…€ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ê²€í† í•˜ì„¸ìš”. ë‹¤ìŒ ì„¸ë¶€ ì‚¬í•­ì„
    ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤.:

    - ë°ì´í„° í”„ë ˆì„ì— ëŒ€í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©´ ê²°ê³¼ëŠ” ìƒˆ ë°ì´í„°
      í”„ë ˆì„ì…ë‹ˆë‹¤(ì´ ê²½ìš° **df** ë°ì´í„° í”„ë ˆì„ì—ì„œ ì—´ì˜ íŠ¹ì • í•˜ìœ„
      ì§‘í•©ì„ ì„ íƒí•˜ì—¬ ìƒˆ **ê³ ê°** ë°ì´í„° í”„ë ˆì„ì´ ìƒì„±ë¨)

    - Dataframeì€ í¬í•¨ëœ ë°ì´í„°ë¥¼ ìš”ì•½í•˜ê³  í•„í„°ë§í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”
      **count** ë° **distinct**ì™€ ê°™ì€ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

    &nbsp;

    - dataframe\['Field1', 'Field2', ...\]Â êµ¬ë¬¸ì€ ì—´ì˜ í•˜ìœ„ ì§‘í•©ì„
      ì •ì˜í•˜ëŠ” ì•½ì‹ ë°©ë²•ì…ë‹ˆë‹¤. **select**Â ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ
      ìœ„ ì½”ë“œì˜ ì²« ë²ˆì§¸ ì¤„ì€Â customers = df.select("CustomerName",
      "Email") ë¡œ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image39.png)

3.  ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê³  cellì˜ ëª¨ë“  ì½”ë“œë¥¼ ë‹¤ìŒ ì½”ë“œë¡œ ë°”ê¾¼ í›„ **â–· Run
    cell** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”:

> CodeCopy
>
> customers = df.select("CustomerName",
> "Email").where(df\['Item'\]=='Road-250 Red, 52')
>
> print(customers.count())
>
> print(customers.distinct().count())
>
> display(customers.distinct())

4.  ìˆ˜ì •ëœ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ***Road-250 Red, 52*** ì œí’ˆì„ êµ¬ë§¤í•œ ê³ ê°ì„
    ë´…ë‹ˆë‹¤. í•œ í•¨ìˆ˜ì˜ ì¶œë ¥ì´ ë‹¤ìŒ í•¨ìˆ˜ì˜ ì…ë ¥ì´ ë˜ë„ë¡ ì—¬ëŸ¬ í•¨ìˆ˜ë¥¼ í•¨ê»˜
    "**ì—°ê²°**"í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ - ì´ ê²½ìš° **select** ë©”ì„œë“œì— ì˜í•´ ìƒì„±ëœ
    ë°ì´í„° í”„ë ˆì„ì€ í•„í„°ë§ ê¸°ì¤€ì„ ì ìš©í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” **where** ë©”ì„œë“œ
    ì˜ ì†ŒìŠ¤ ë°ì´í„° í”„ë ˆì„ì…ë‹ˆë‹¤.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image40.png)

## ì‘ì—… 2: Aggregate and group data in a dataframe

1.  \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì€ í›„ **Run cell**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

> CodeCopy
>
> productSales = df.select("Item", "Quantity").groupBy("Item").sum()
>
> display(productSales)
>
> ![](./media/image41.png)

2.  ê²°ê³¼ì—ëŠ” ì œí’ˆë³„ë¡œ ê·¸ë£¹í™”ëœ ì£¼ë¬¸ ìˆ˜ëŸ‰ì˜ í•©ê³„ê°€ í‘œì‹œë©ë‹ˆë‹¤.
    **groupBy** ë©”ì„œë“œ ëŠ” *Item*ë³„ë¡œ í–‰ì„ ê·¸ë£¹í™”í•˜ê³  í›„ì† **í•©ê³„** ì§‘ê³„
    í•¨ìˆ˜ëŠ” ë‚˜ë¨¸ì§€ ëª¨ë“  ìˆ«ì ì—´(ì´ ê²½ìš° Quantity)ì— ì ìš©ë©ë‹ˆë‹¤

3.  \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì€ í›„ **Run cell**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image42.png)

> **CodeCopy**
>
> from pyspark.sql.functions import \*
>
> yearlySales =
> df.select(year("OrderDate").alias("Year")).groupBy("Year").count().orderBy("Year")
>
> display(yearlySales)
>
> ![](./media/image43.png)

4.  ê²°ê³¼ì—ëŠ” ì—°ê°„ íŒë§¤ ì£¼ë¬¸ ìˆ˜ê°€ í‘œì‹œë©ë‹ˆë‹¤. **select** ë©”ì„œë“œ ì—ëŠ”
    **OrderDate** í•„ë“œ ì˜ ì—°ë„ êµ¬ì„± ìš”ì†Œë¥¼ ì¶”ì¶œí•˜ëŠ” SQL *ì—°ë„* í•¨ìˆ˜ê°€
    í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤(ì´ ë•Œë¬¸ì— ì½”ë“œì—ëŠ” Spark SQL ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ í•¨ìˆ˜ë¥¼
    ê°€ì ¸ì˜¤ëŠ” import ë¬¸ì´ í¬í•¨ë˜ì–´ ìˆìŒ). ê·¸ëŸ° ë‹¤ìŒ **ë³„ì¹­** ë©”ì„œë“œë¥¼
    ì‚¬ìš©í•˜ì—¬ ì¶”ì¶œëœ ì—°ë„ ê°’ì— ì—´ ì´ë¦„ì„ í• ë‹¹í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë°ì´í„°ëŠ”
    íŒŒìƒëœ **Year** ì—´ë³„ë¡œ ê·¸ë£¹í™” ë˜ê³  ê° ê·¸ë£¹ì˜ í–‰ ìˆ˜ê°€ ê³„ì‚°ëœ í›„
    ë§ˆì§€ë§‰ìœ¼ë¡œ **orderBy** ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ ë°ì´í„° í”„ë ˆì„ì„
    ì •ë ¬í•©ë‹ˆë‹¤.

# ì—°ìŠµ 3: Sparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° íŒŒì¼ ë³€í™˜

ë°ì´í„° ì—”ì§€ë‹ˆì–´ì˜ ì¼ë°˜ì ì¸ ì‘ì—…ì€ íŠ¹ì • í˜•ì‹ì´ë‚˜ êµ¬ì¡°ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ 
ì¶”ê°€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë˜ëŠ” ë¶„ì„ì„ ìœ„í•´ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ì‘ì—… 1: ë°ì´í„° í”„ë ˆì„ ë©”ì„œë“œ ë° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë³€í™˜

1.  \+ Codeë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.

**CodeCopy**

> from pyspark.sql.functions import \*
>
> \## Create Year and Month columns
>
> transformed_df = df.withColumn("Year",
> year(col("OrderDate"))).withColumn("Month", month(col("OrderDate")))
>
> \# Create the new FirstName and LastName fields
>
> transformed_df = transformed_df.withColumn("FirstName",
> split(col("CustomerName"), " ").getItem(0)).withColumn("LastName",
> split(col("CustomerName"), " ").getItem(1))
>
> \# Filter and reorder columns
>
> transformed_df = transformed_df\["SalesOrderNumber",
> "SalesOrderLineNumber", "OrderDate", "Year", "Month", "FirstName",
> "LastName", "Email", "Item", "Quantity", "UnitPrice", "Tax"\]
>
> \# Display the first five orders
>
> display(transformed_df.limit(5))
>
> ![](./media/image44.png)

2.  **ì½”ë“œë¥¼ ì‹¤í–‰**í•˜ì—¬ ë‹¤ìŒ ë³€í™˜ì„ ì‚¬ìš©í•˜ì—¬ ì›ë˜ ì£¼ë¬¸ ë°ì´í„°ì—ì„œ ìƒˆ
    ë°ì´í„° í”„ë ˆì„ì„ ìƒì„±í•˜ì„¸ìš”:

    - **OrderDate** ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ **YearÂ **ë°
      **Month**ì„**Â **ì¶”ê°€í•©ë‹ˆë‹¤.

    - **CustomerName** ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ **FirstName** ë° **LastName** ì—´ì„
      ì¶”ê°€í•©ë‹ˆë‹¤.

    - ì—´ì„ í•„í„°ë§í•˜ê³  ìˆœì„œë¥¼ ë³€ê²½í•˜ì—¬ **CustomerName** ì—´ì„ ì œê±°í•©ë‹ˆë‹¤.

> ![](./media/image45.png)

3.  ì¶œë ¥ì„ ê²€í† í•˜ê³  ë°ì´í„°ì— ëŒ€í•œ ë³€í™˜ì´ ì´ë£¨ì–´ì¡ŒëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image46.png)

Spark SQL ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ í–‰ì„ í•„í„°ë§í•˜ê³ , ì—´ì„ íŒŒìƒ,
ì œê±°, ì´ë¦„ ë°”ê¾¸ê³ , ê¸°íƒ€ í•„ìš”í•œ ë°ì´í„° ìˆ˜ì •ì„ ì ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë³€í™˜í•  ìˆ˜
ìˆìŠµë‹ˆë‹¤.

**íŒ**: Dataframe ê°ì²´ì˜ ë©”ì„œë“œì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´Â [*Spark
dataframe
documentation*](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html)ë¥¼
ì°¸ì¡°í•˜ì„¸ìš”.

## ì‘ì—… 2: ë³€í™˜ëœ ë°ì´í„° ì €ì¥

1.  **ë‹¤ìŒ ì½”ë“œë¡œ ìƒˆ ì…€ì„ ì¶”ê°€**í•˜ì—¬ ë³€í™˜ëœ ë°ì´í„° í”„ë ˆì„ì„ Parquet
    í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ì„¸ìš” (ì´ë¯¸ ìˆëŠ” ê²½ìš° ë°ì´í„° ë®ì–´ì“°ê¸°). ì…€ì„ ì‹¤í–‰í•˜ê³ 
    ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë¦¬ì„¸ìš”.

> CodeCopy
>
> transformed_df.write.mode("overwrite").parquet('Files/transformed_data/orders')
>
> print ("Transformed data saved!")
>
> **ì°¸ê³ **: ì¼ë°˜ì ìœ¼ë¡œ *Parquet* í˜•ì‹ì€ ì¶”ê°€ ë¶„ì„ ë˜ëŠ” ë¶„ì„ ì €ì¥ì†Œë¡œì˜
> ìˆ˜ì§‘ì— ì‚¬ìš©í•  ë°ì´í„° íŒŒì¼ì— ì„ í˜¸ë©ë‹ˆë‹¤. Parquetì€ ëŒ€ë¶€ë¶„ì˜ ëŒ€ê·œëª¨
> ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì—ì„œ ì§€ì›ë˜ëŠ” ë§¤ìš° íš¨ìœ¨ì ì¸ í˜•ì‹ì…ë‹ˆë‹¤. ì‹¤ì œë¡œ
> ë•Œë¡œëŠ” ë°ì´í„° ë³€í™˜ ìš”êµ¬ ì‚¬í•­ì´ ë‹¨ìˆœíˆ ë‹¤ë¥¸ í˜•ì‹(ì˜ˆ: CSV)ì—ì„œ Parquetë¡œ
> ë°ì´í„°ë¥¼ ë³€í™˜í•˜ëŠ” ê²ƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
>
> ![](./media/image47.png)
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image48.png)

2.  ì™¼ìª½ì˜ **Lakehouse** íƒìƒ‰ê¸° ì°½ì—ì„œ **... Files** ë…¸ë“œì˜ ë©”ë‰´ì—ì„œ
    **Refresh**ì„ ì„ íƒí•˜ì„¸ìš”.

> ![](./media/image49.png)

3.  **transformed_data** í´ë”ë¥¼ í´ë¦­í•˜ì—¬ **orders**ë¼ëŠ” ìƒˆ í´ë”ê°€
    í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ í•˜ë©°, ì´ í´ë”ì—ëŠ” í•˜ë‚˜ ì´ìƒì˜ **Parquet
    files**ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image50.png)

4.  \+ **Code** ë‹¤ìŒ ì½”ë“œë¥¼ í´ë¦­í•˜ì—¬ **transformed_data -\> orders**
    í´ë”ì˜ parquet íŒŒì¼ì—ì„œ ìƒˆ ë°ì´í„° í”„ë ˆì„ì„ ë¡œë“œí•˜ì„¸ìš”:

> **CodeCopy**
>
> orders_df =
> spark.read.format("parquet").load("Files/transformed_data/orders")
>
> display(orders_df)
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image51.png)

5.  ì…€ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ì— parquet íŒŒì¼ì—ì„œ ë¡œë“œëœ ì£¼ë¬¸ ë°ì´í„°ê°€
    í‘œì‹œë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image52.png)

## ì‘ì—… 3: íŒŒí‹°ì…˜ëœ íŒŒì¼ì— ë°ì´í„° ì €ì¥

1.  ìƒˆ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¡œ **+ Code**ë¥¼ í´ë¦­í•˜ì„¸ìš”. ë°ì´í„°
    í”„ë ˆì„ì„ ì €ì¥í•˜ê³  ë°ì´í„°ë¥¼ **Year**Â ë°**Month**ë¡œ ë¶„í• í•˜ì„¸ìš”. ì…€ì„
    ì‹¤í–‰í•˜ê³  ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë¦¬ì„¸ìš”.

> CodeCopy
>
> orders_df.write.partitionBy("Year","Month").mode("overwrite").parquet("Files/partitioned_data")
>
> print ("Transformed data saved!")
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image53.png)
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image54.png)

2.  ì™¼ìª½ì˜ **Lakehouse** íƒìƒ‰ê¸° ì°½ì—ì„œ ... **Files** ë…¸ë“œì˜ ë©”ë‰´ì—ì„œ
    **Refresh**ì„ ì„ íƒí•˜ì„¸ìš”

![](./media/image55.png)

3.  **partitioned_orders** í´ë”ë¥¼ í™•ì¥í•˜ì—¬ **Year=xxxx**ë¼ëŠ” í´ë”ì˜ ê³„ì¸µ
    êµ¬ì¡°ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ê° í´ë”ì—ëŠ” **Month=xxxx**ë¼ëŠ”
    í´ë”ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ì›” í´ë”ì—ëŠ” í•´ë‹¹ ì›”ì˜ ì£¼ë¬¸ì´ í¬í•¨ëœ
    ìª½ëª¨ì´ ì„¸ê³µ ë§ˆë£¨ íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image56.png)

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image57.png)

> ë°ì´í„° íŒŒì¼ ë¶„í• ì€ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ”
> ì¼ë°˜ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ê³  ë°ì´í„°ë¥¼ ë” ì‰½ê²Œ
> í•„í„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

4.  ìƒˆ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¡œ **+ Code**ë¥¼ í´ë¦­í•˜ì—¬
    **orders.parquet** íŒŒì¼ì—ì„œ ìƒˆ ë°ì´í„° í”„ë ˆì„ì„ ë¡œë“œí•˜ì„¸ìš”:

> CodeCopy
>
> orders_2021_df =
> spark.read.format("parquet").load("Files/partitioned_data/Year=2021/Month=\*")
>
> display(orders_2021_df)

5.  ì…€ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ì— 2021ë…„ íŒë§¤ì— ëŒ€í•œ ì£¼ë¬¸ ë°ì´í„°ê°€ í‘œì‹œë˜ëŠ”ì§€
    í™•ì¸í•˜ì„¸ìš”. ê²½ë¡œ (**Year** ë° **Month**)ì— ì§€ì •ëœ ë¶„í•  ì—´ì€ ë°ì´í„°
    í”„ë ˆì„ì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image58.png)

# **ì—°ìŠµ 3: í…Œì´ë¸” ë° SQLì— ëŒ€í•œ ì‘ì—…**

ë³´ì•˜ë“¯ì´ dataframe ê°ì²´ì˜ ê¸°ë³¸ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ë§¤ìš°
íš¨ê³¼ì ìœ¼ë¡œ ì¿¼ë¦¬í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë§ì€ ë°ì´í„° ë¶„ì„ê°€ëŠ” SQL
êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” í…Œì´ë¸”ë¡œ ì‘ì—…í•˜ëŠ” ê²ƒì´ ë” í¸í•©ë‹ˆë‹¤. Spark
ëŠ” ê´€ê³„í˜• í…Œì´ë¸”ì„ ì •ì˜í•  ìˆ˜ ìˆëŠ” ë©”íƒ€ìŠ¤í† ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. dataframe
ê°œì²´ë¥¼ ì œê³µí•˜ëŠ” Spark SQL ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” SQL ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ë©”íƒ€ìŠ¤í† ì–´ì˜
í…Œì´ë¸”ì„ ì¿¼ë¦¬í•˜ëŠ” ê²ƒë„ ì§€ì›í•©ë‹ˆë‹¤. Sparkì˜ ì´ëŸ¬í•œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ ë°ì´í„°
ë ˆì´í¬ì˜ ìœ ì—°ì„±ì„ ê´€ê³„í˜• ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ì˜ êµ¬ì¡°í™”ëœ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ë°
SQL ê¸°ë°˜ ì¿¼ë¦¬ì™€ ê²°í•©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ "Data Lakehouse"ë¼ëŠ” ìš©ì–´ê°€
ì‚¬ìš©ë©ë‹ˆë‹¤.

## ì‘ì—… 1: ê´€ë¦¬ë˜ëŠ” í…Œì´ë¸” ìƒì„±í•˜ê¸°

Spark ë©”íƒ€ìŠ¤í† ì–´ì˜ í…Œì´ë¸”ì€ ë°ì´í„° ë ˆì´í¬ì˜ íŒŒì¼ì— ëŒ€í•œ ê´€ê³„í˜•
ì¶”ìƒí™”ì…ë‹ˆë‹¤. í…Œì´ë¸”ì€ *ê´€ë¦¬*(ì´ ê²½ìš° íŒŒì¼ì´ ë©”íƒ€ìŠ¤í† ì–´ì— ì˜í•´ ê´€ë¦¬ë¨)
ë˜ëŠ” *ì™¸ë¶€*(í…Œì´ë¸”ì´ ë©”íƒ€ìŠ¤í† ì–´ì™€ ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë°ì´í„° ë ˆì´í¬ì˜
íŒŒì¼ ìœ„ì¹˜ë¥¼ ì°¸ì¡°í•¨)ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1.  ìƒˆ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³  ë…¸íŠ¸ë¶ì— + **Code**ì…€ì„ í´ë¦­í•œ í›„ ë‹¤ìŒ ì½”ë“œë¥¼
    ì…ë ¥í•˜ë©´ íŒë§¤ ì£¼ë¬¸ ë°ì´í„°ì˜ ë°ì´í„° í”„ë ˆì„ì´ **salesorder**ë¼ëŠ”
    í…Œì´ë¸”ë¡œ ì €ì¥ë©ë‹ˆë‹¤:

> CodeCopy
>
> \# Create a new table
>
> df.write.format("delta").saveAsTable("salesorders")
>
> \# Get the table description
>
> spark.sql("DESCRIBE EXTENDED salesorders").show(truncate=False)

**ì°¸ê³ **: ì´ ì˜ˆì œì— ëŒ€í•´ ëª‡ ê°€ì§€ ì‚¬í•­ì— ì£¼ëª©í•  ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. ì²«ì§¸,
ëª…ì‹œì  ê²½ë¡œê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë¯€ë¡œ í…Œì´ë¸”ì˜ íŒŒì¼ì€ ë©”íƒ€ìŠ¤í† ì–´ì—ì„œ
ê´€ë¦¬ë©ë‹ˆë‹¤. ë‘˜ì§¸, í…Œì´ë¸”ì€ **delta**í˜•ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤. ì—¬ëŸ¬ íŒŒì¼
í˜•ì‹(CSV, Parquet, Avro ë“±)ì„ ê¸°ë°˜ìœ¼ë¡œ í…Œì´ë¸”ì„ ë§Œë“¤ ìˆ˜ ìˆì§€ë§Œ *delta
lake*ëŠ” íŠ¸ëœì­ì…˜, í–‰ ë²„ì „ ê´€ë¦¬ ë° ê¸°íƒ€ ìœ ìš©í•œ ê¸°ëŠ¥ì— ëŒ€í•œ ì§€ì›ì„
í¬í•¨í•˜ì—¬ í…Œì´ë¸”ì— ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” Spark ê¸°ìˆ ì…ë‹ˆë‹¤.
Delta í˜•ì‹ìœ¼ë¡œ í…Œì´ë¸”ì„ ë§Œë“œëŠ” ê²ƒì€ Fabricì˜ Data Lakehouseì—
ì„ í˜¸ë©ë‹ˆë‹¤.

2.  ì½”ë“œ ì…€ì„ ì‹¤í–‰í•˜ê³  ìƒˆ í…Œì´ë¸”ì˜ ì •ì˜ë¥¼ ì„¤ëª…í•˜ëŠ” ì¶œë ¥ì„ ê²€í† í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image59.png)

3.  **Lakehouse íƒìƒ‰ê¸°** ì°½ì˜ **...Tables**Â í´ë”ì˜ ë©”ë‰´ì—ì„œ
    **Refresh**ì„ ì„ íƒí•˜ì„¸ìš”.

![](./media/image60.png)

4.  **TablesÂ **ë…¸ë“œë¥¼ í™•ì¥í•˜ê³  **salesorders** í…Œì´ë¸”ì´ ë§Œë“¤ì–´ì¡ŒëŠ”ì§€
    í™•ì¸í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image61.png)

5.  **salesorders** í…Œì´ë¸” ì˜†ì— ë§ˆìš°ìŠ¤ë¥¼ ë†“ì€ í›„ ê°€ë¡œ ì¤„ì„í‘œ(...)ë¥¼
    í´ë¦­í•˜ì„¸ìš”. **Load data**ë¥¼ íƒìƒ‰í•˜ê³  í´ë¦­í•œ í›„ **Spark**ë¥¼
    ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image62.png)

6.  â–· **Run cell** ë²„íŠ¼ì„ í´ë¦­í•˜ê³  Spark SQL ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬
    PySpark ì½”ë“œì˜ **salesorder** í…Œì´ë¸” ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ í¬í•¨í•˜ê³ 
    ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ë°ì´í„° í”„ë ˆì„ì— ë¡œë“œí•˜ì„¸ìš”.

> CodeCopy
>
> df = spark.sql("SELECT \* FROM \[your_lakehouse\].salesorders LIMIT
> 1000")
>
> display(df)

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image63.png)

## ì‘ì—… 2: ì™¸ë¶€ í…Œì´ë¸” ìƒì„±

ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°ê°€ Lakehouseì˜ ë©”íƒ€ìŠ¤í† ì–´ì— ì •ì˜ë˜ì–´ ìˆì§€ë§Œ ë°ì´í„°
íŒŒì¼ì€ ì™¸ë¶€ ìœ„ì¹˜ì— ì €ì¥ë˜ëŠ” *ì™¸ë¶€ í…Œì´ë¸”ì„* ë§Œë“¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

1.  ì²« ë²ˆì§¸ ì½”ë“œ ì…€ì—ì„œ ë°˜í™˜ëœ ê²°ê³¼ ì•„ë˜ì—ì„œ **+ CodeÂ **ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬
    ìƒˆ ì½”ë“œ ì…€ì´ ì—†ëŠ” ê²½ìš° ìƒˆ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ì„¸ìš”. ìƒˆ ì…€ì— ë‹¤ìŒ ì½”ë“œë¥¼
    ì…ë ¥í•˜ì„¸ìš”.

CodeCopy

> df.write.format("delta").saveAsTable("external_salesorder",
> path="\<abfs_path\>/external_salesorder")

![A screenshot of a computer Description automatically
generated](./media/image64.png)

2.  **Lakehouse íƒìƒ‰ê¸°** ì°½ì˜ **...**ë©”ë‰´ë¥¼ í´ë¦­í•˜ì—¬ **Files**Â í´ë”ì—ì„œ
    ë©”ëª¨ì¥ì—ì„œ **Copy ABFS pathë¥¼** ì„ íƒí•˜ì„¸ìš”.

> ABFS ê²½ë¡œëŠ” Lakehouseì— ëŒ€í•œ OneLake ìŠ¤í† ë¦¬ì§€ì— ìˆëŠ” **FilesÂ **í´ë”ì—
> ëŒ€í•œ ì •ê·œí™”ëœ ê²½ë¡œì…ë‹ˆë‹¤:

abfss://dp_Fabric29@onelake.dfs.fabric.microsoft.com/Fabric_lakehouse.Lakehouse/Files/external_salesorder

![A screenshot of a computer Description automatically
generated](./media/image65.png)

3.  ì´ì œ ì½”ë“œ ì…€ë¡œ ì´ë™í•˜ì—¬ **\<abfs_path\>**ë¥¼ ë©”ëª¨ì¥ì— ë³µì‚¬í•œ
    **path**ë¡œ ë°”ê¾¸ë©´ ì½”ë“œê°€ ë°ì´í„° í”„ë ˆì„ì„ íŒŒì¼ í´ë” ìœ„ì¹˜ì˜
    **external_salesorder**ë¼ëŠ” í´ë”ì— ë°ì´í„° íŒŒ **Files**ì¼ì´ ìˆëŠ” ì™¸ë¶€
    í…Œì´ë¸”ë¡œ ì €ì¥ë©ë‹ˆë‹¤. ì „ì²´ ê²½ë¡œëŠ” ë‹¤ìŒê³¼ ìœ ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤.

abfss://dp_Fabric29@onelake.dfs.fabric.microsoft.com/Fabric_lakehouse.Lakehouse/Files/external_salesorder

4.  ì…€ ì™¼ìª½ì— ìˆëŠ” **â–· (*Run cell*)** ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image66.png)

5.  **Lakehouse íƒìƒ‰ê¸°** ì°½ì˜ **...Tables** í´ë”ì˜ ë©”ë‰´ì—ì„œ
    **Refresh**ì„ ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image67.png)

6.  **TablesÂ **ë…¸ë“œë¥¼ í™•ì¥í•˜ê³  **external_salesorder** í…Œì´ë¸”ì´
    ë§Œë“¤ì–´ì¡ŒëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image68.png)

7.  ì™¼ìª½ì˜ **Lakehouse** íƒìƒ‰ê¸° ì°½ì—ì„œ ... **Files** ë…¸ë“œì˜ ë©”ë‰´ì—ì„œ
    **Refresh**ì„ ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image69.png)

8.  **Files** ë…¸ë“œë¥¼ í™•ì¥í•˜ê³  í…Œì´ë¸”ì˜ ë°ì´í„° íŒŒì¼ì— ëŒ€í•œ
    **external_salesorder** í´ë”ê°€ ë§Œë“¤ì–´ì¡ŒëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image70.png)

## ì‘ì—… 3: ê´€ë¦¬ë˜ëŠ” í…Œì´ë¸”ê³¼ ì™¸ë¶€ í…Œì´ë¸” ë¹„êµ

ê´€ë¦¬í˜• í…Œì´ë¸”ê³¼ ì™¸ë¶€ í…Œì´ë¸”ì˜ ì°¨ì´ì ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

1.  ì½”ë“œ ì…€ì—ì„œ ë°˜í™˜ëœ ê²°ê³¼ ì•„ë˜ì—ì„œ **+ CodeÂ **ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆ ì½”ë“œ
    ì…€ì„ ì¶”ê°€í•˜ì„¸ìš”. ì•„ë˜ ì½”ë“œë¥¼ ì½”ë“œ ì…€ì— ë³µì‚¬í•˜ê³  ì…€ ì™¼ìª½ì— ìˆëŠ”
    **â–·*(Run cell***) ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.

> SqlCopy
>
> %%sql
>
> DESCRIBE FORMATTED salesorders;
>
> ![](./media/image71.png)

2.  ê²°ê³¼ì—ì„œ **/Tables/salesorders**ë¡œ ëë‚˜ëŠ” Lakehouseì˜ OneLake
    ìŠ¤í† ë¦¬ì§€ì— ëŒ€í•œ ê²½ë¡œì—¬ì•¼ í•˜ëŠ” í…Œì´ë¸”ì˜ **Location** ì†ì„±ì„ ë´…ë‹ˆë‹¤
    (ì „ì²´ ê²½ë¡œë¥¼ ë³´ë ¤ë©´ **Â Data type** ì—´ì„ ë„“í˜€ì•¼ í•  ìˆ˜ ìˆìŒ).

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image72.png)

3.  ì—¬ê¸°ì— í‘œì‹œëœ ëŒ€ë¡œ **external_saleorder** í…Œì´ë¸”ì˜ ì„¸ë¶€ ì •ë³´ë¥¼
    í‘œì‹œí•˜ë„ë¡**DESCRIBE**Â ëª…ë ¹ì„ ìˆ˜ì •í•˜ì„¸ìš”.

4.  ì½”ë“œ ì…€ì—ì„œ ë°˜í™˜ëœ ê²°ê³¼ ì•„ë˜ì—ì„œ **+ CodeÂ **ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆ ì½”ë“œ
    ì…€ì„ ì¶”ê°€í•˜ì„¸ìš”. ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ê³  ì…€ ì™¼ìª½ì— ìˆëŠ” **â–· (Run
    cell**) ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.

> SqlCopy
>
> %%sql
>
> DESCRIBE FORMATTED external_salesorder;

5.  ê²°ê³¼ì—ì„œ **/Files/external_saleorder**ë¡œ ëë‚˜ëŠ” Lakehouseì˜ OneLake
    ìŠ¤í† ë¦¬ì§€ì— ëŒ€í•œ ê²½ë¡œì—¬ì•¼ í•˜ëŠ” í…Œì´ë¸”ì˜ **Location** ì†ì„±ì„
    ë´…ë‹ˆë‹¤(ì „ì²´ ê²½ë¡œë¥¼ ë³´ë ¤ë©´ **Data type** ì—´ì„ ë„“í˜€ì•¼ í•  ìˆ˜ ìˆìŒ).

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image73.png)

## ì‘ì—…4: ì…€ì—ì„œ SQL ì½”ë“œ ì‹¤í–‰

PySpark ì½”ë“œê°€ í¬í•¨ëœ ì…€ì— SQL ë¬¸ì„ í¬í•¨í•  ìˆ˜ ìˆëŠ” ê²ƒì´ ìœ ìš©í•˜ì§€ë§Œ
ë°ì´í„° ë¶„ì„ê°€ëŠ” ì¢…ì¢… SQLì—ì„œ ì§ì ‘ ì‘ì—…í•˜ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤.

1.  ë…¸íŠ¸ë¶ì— ëŒ€í•œ **+ Code**ì…€ì„ í´ë¦­í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. **â–·
    Run cellÂ **ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ê²°ê³¼ë¥¼ ê²€í† í•˜ì„¸ìš”. ë‹¤ìŒì„ ê´€ì°°í•˜ì„¸ìš”.

    - ì…€ ì‹œì‘ ë¶€ë¶„ì˜Â %%sqlÂ ì¤„(ë§¤ì§ì´ë¼ê³  í•¨)ì€ PySpark ëŒ€ì‹  Spark SQL
      ì–¸ì–´ ëŸ°íƒ€ì„ì„ ì‚¬ìš©í•˜ì—¬ ì´ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•´ì•¼ í•¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

    - SQL ì½”ë“œëŠ” ì´ì „ì— ë§Œë“  **salesorders** í…Œì´ë¸”ì„ ì°¸ì¡°í•©ë‹ˆë‹¤.

    - SQL ì¿¼ë¦¬ì˜ ì¶œë ¥ì€ ì…€ ì•„ë˜ì— ê²°ê³¼ë¡œ ìë™ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.

> SqlCopy
>
> %%sql
>
> SELECT YEAR(OrderDate) AS OrderYear,
>
> SUM((UnitPrice \* Quantity) + Tax) AS GrossRevenue
>
> FROM salesorders
>
> GROUP BY YEAR(OrderDate)
>
> ORDER BY OrderYear;

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image74.png)

**ì°¸ê³ :** Spark SQL ë° ë°ì´í„° í”„ë ˆì„ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€[*Spark SQL
documentation*](https://spark.apache.org/docs/2.2.0/sql-programming-guide.html)ë¥¼
ì°¸ì¡°í•˜ì„¸ìš”.

# ì—°ìŠµ 4: Sparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì‹œê°í™”

ì†ë‹´ì— ë”°ë¥´ë©´ ì‚¬ì§„ í•œ ì¥ì´ ì²œ ë§ˆë”” ë§ë³´ë‹¤ ê°€ì¹˜ê°€ ìˆìœ¼ë©°, ì°¨íŠ¸ëŠ” ì¢…ì¢… ì²œ
í–‰ì˜ ë°ì´í„°ë³´ë‹¤ ë‚«ìŠµë‹ˆë‹¤. Fabricì˜ ë…¸íŠ¸ë¶ì—ëŠ” ë°ì´í„° í”„ë ˆì„ ë˜ëŠ” Spark
SQL ì¿¼ë¦¬ì—ì„œ í‘œì‹œë˜ëŠ” ë°ì´í„°ì— ëŒ€í•œ ê¸°ë³¸ ì œê³µ ì°¨íŠ¸ ë³´ê¸°ê°€ í¬í•¨ë˜ì–´
ìˆì§€ë§Œ í¬ê´„ì ì¸ ì°¨íŠ¸ ì‘ì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜
**matplotlib** ë° **seaborn**ê³¼ ê°™ì€ Python ê·¸ë˜í”½ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¥¼
ì‚¬ìš©í•˜ì—¬ ë°ì´í„° í”„ë ˆì„ì˜ ë°ì´í„°ì—ì„œ ì°¨íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì‘ì—…1: ê²°ê³¼ë¥¼ ì°¨íŠ¸ë¡œ ë³´ê¸°

1.  ë…¸íŠ¸ë¶ì— ëŒ€í•œ **+ Code**ì…€ì„ í´ë¦­í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. **â–·
    Run cellÂ **ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ì´ì „ì— ìƒì„±í•œ **salesordersÂ **ë³´ê¸°ì˜
    ë°ì´í„°ê°€ ë°˜í™˜ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

> SqlCopy
>
> %%sql
>
> SELECT \* FROM salesorders

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image75.png)

2.  ì…€ ì•„ë˜ì˜ ê²°ê³¼ ì„¹ì…˜ì—ì„œ **View** ì˜µì…˜ì„ **TableÂ **ì—ì„œ + **New
    chart**ë¡œ ë³€ê²½í•˜ì„¸ìš”.

![](./media/image76.png)

3.  ì°¨íŠ¸ì˜ ì˜¤ë¥¸ìª½ ìœ„ì— ìˆëŠ” **Start editing**Â ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ì˜
    ì˜µì…˜ ì°½ì„ í‘œì‹œí•˜ì„¸ìš”. ë‹¤ìŒê³¼ ê°™ì´ ì˜µì…˜ì„ ì„¤ì •í•˜ê³  **Apply**ì„
    ì„ íƒí•˜ì„¸ìš”:

    - **Chart type**: Bar chart

    - **Key**: Item

    - **Values**: Quantity

    - **Series Group**:Â *leave blank*

    - **Aggregation**: Sum

    - **Stacked**:Â *Unselected*

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image77.png)

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image78.png)

4.  ì°¨íŠ¸ê°€ ë‹¤ìŒê³¼ ìœ ì‚¬í•œì§€ í™•ì¸í•˜ì„¸ìš”.

> ![](./media/image79.png)

## ì‘ì—… 2: matplotlib ì‹œì‘í•˜ê¸°

1.  \+ Codeë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”. ì½”ë“œë¥¼
    **ì‹¤í–‰**í•˜ê³  ì—°ê°„ ìˆ˜ìµì´ í¬í•¨ëœ Spark ë°ì´í„° í”„ë ˆì„ì„ ë°˜í™˜í•˜ëŠ”ì§€
    í™•ì¸í•˜ì„¸ìš”.

> CodeCopy
>
> sqlQuery = "SELECT CAST(YEAR(OrderDate) AS CHAR(4)) AS OrderYear, \\
>
> SUM((UnitPrice \* Quantity) + Tax) AS GrossRevenue \\
>
> FROM salesorders \\
>
> GROUP BY CAST(YEAR(OrderDate) AS CHAR(4)) \\
>
> ORDER BY OrderYear"
>
> df_spark = spark.sql(sqlQuery)
>
> df_spark.show()
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image80.png)

2.  ë°ì´í„°ë¥¼ ì°¨íŠ¸ë¡œ ì‹œê°í™”í•˜ê¸° ìœ„í•´ **matplotlib** Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼
    ì‚¬ìš©í•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‹¤ë¥¸ ë§ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê¸°ë°˜ì´
    ë˜ëŠ” í•µì‹¬ í”Œë¡œíŒ… ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë©° ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë° í° ìœ ì—°ì„±ì„
    ì œê³µí•©ë‹ˆë‹¤.

3.  \+ Codeë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.

**CodeCopy**

> from matplotlib import pyplot as plt
>
> \# matplotlib requires a Pandas dataframe, not a Spark one
>
> df_sales = df_spark.toPandas()
>
> \# Create a bar plot of revenue by year
>
> plt.bar(x=df_sales\['OrderYear'\], height=df_sales\['GrossRevenue'\])
>
> \# Display the plot
>
> plt.show()

![A screenshot of a computer Description automatically
generated](./media/image81.png)

5.  **Run cell** ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ê° ì—°ë„ì˜ ì´ ìˆ˜ìµì´ í¬í•¨ëœ ì„¸ë¡œ ë§‰ëŒ€í˜•
    ì°¨íŠ¸ë¡œ êµ¬ì„±ëœ ê²°ê³¼ë¥¼ ê²€í† í•˜ì„¸ìš”. ì´ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ëœ ì½”ë“œì˜
    ë‹¤ìŒ ê¸°ëŠ¥ì— ìœ ì˜í•˜ì„¸ìš”:

    - **matplotlib** ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ëŠ” Pandas ë°ì´í„° í”„ë ˆì„ì´ í•„ìš”í•˜ë¯€ë¡œ
      Spark SQL ì¿¼ë¦¬ì—ì„œ ë°˜í™˜ëœ *Spark* ë°ì´í„° í”„ë ˆì„ì„ ì´ í˜•ì‹ìœ¼ë¡œ
      ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

    - **matplotlib** ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•µì‹¬ì—ëŠ” **pyplot** ê°ì²´ê°€ ìˆìŠµë‹ˆë‹¤.
      ì´ê²ƒì€ ëŒ€ë¶€ë¶„ì˜ í”Œë¡œíŒ… ê¸°ëŠ¥ì˜ ê¸°ì´ˆì…ë‹ˆë‹¤.

    - ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¸í•´ ì‚¬ìš© ê°€ëŠ¥í•œ ì°¨íŠ¸ê°€ ìƒì„±ë˜ì§€ë§Œ ì‚¬ìš©ì ì§€ì •í•  ìˆ˜
      ìˆëŠ” ë²”ìœ„ê°€ ìƒë‹¹íˆ í½ë‹ˆë‹¤.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image82.png)

6.  ë‹¤ìŒê³¼ ê°™ì´ ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê³  **cell**ì˜ ëª¨ë“  ì½”ë“œë¥¼
    ë‹¤ìŒ ì½”ë“œë¡œ ë°”ê¾¼ í›„ **â–· Run cell**ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ì¶œë ¥ì„ ê²€í† í•˜ì„¸ìš”.

> CodeCopy
>
> from matplotlib import pyplot as plt
>
> \# Clear the plot area
>
> plt.clf()
>
> \# Create a bar plot of revenue by year
>
> plt.bar(x=df_sales\['OrderYear'\], height=df_sales\['GrossRevenue'\],
> color='orange')
>
> \# Customize the chart
>
> plt.title('Revenue by Year')
>
> plt.xlabel('Year')
>
> plt.ylabel('Revenue')
>
> plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y',
> alpha=0.7)
>
> plt.xticks(rotation=45)
>
> \# Show the figure
>
> plt.show()
>
> ![A screenshot of a computer program AI-generated content may be
> incorrect.](./media/image83.png)
>
> ![A graph with orange bars AI-generated content may be
> incorrect.](./media/image84.png)

7.  ì´ì œ ì°¨íŠ¸ì— ì¡°ê¸ˆ ë” ë§ì€ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤. í”Œë¡¯ì€ ê¸°ìˆ ì ìœ¼ë¡œ
    **Figure**ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ì „ ì˜ˆì œì—ì„œ ê·¸ë¦¼ì€ ì•”ì‹œì ìœ¼ë¡œ
    ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëª…ì‹œ ì ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

8.  ë‹¤ìŒê³¼ ê°™ì´ ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê³  cellì˜ ëª¨ë“  ì½”ë“œë¥¼ ë‹¤ìŒ
    ì½”ë“œë¡œ ë°”ê¾¸ì„¸ìš”.

> CodeCopy
>
> from matplotlib import pyplot as plt
>
> \# Clear the plot area
>
> plt.clf()
>
> \# Create a Figure
>
> fig = plt.figure(figsize=(8,3))
>
> \# Create a bar plot of revenue by year
>
> plt.bar(x=df_sales\['OrderYear'\], height=df_sales\['GrossRevenue'\],
> color='orange')
>
> \# Customize the chart
>
> plt.title('Revenue by Year')
>
> plt.xlabel('Year')
>
> plt.ylabel('Revenue')
>
> plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y',
> alpha=0.7)
>
> plt.xticks(rotation=45)
>
> \# Show the figure
>
> plt.show()

9.  **ì½”ë“œ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰**í•˜ê³  ê²°ê³¼ë¥¼ ë³´ì„¸ìš”. ê·¸ë¦¼ì€ í”Œë¡¯ì˜ ëª¨ì–‘ê³¼
    í¬ê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

> ê·¸ë¦¼ì—ëŠ” ê°ê° ìì²´ ì¶•ì— ìˆëŠ” ì—¬ëŸ¬ í•˜ìœ„ í”Œë¡¯ì´ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ .
>
> ![A screenshot of a computer program AI-generated content may be
> incorrect.](./media/image85.png)
>
> ![A screenshot of a graph AI-generated content may be
> incorrect.](./media/image86.png)

10. ë‹¤ìŒê³¼ ê°™ì´ ì°¨íŠ¸ë¥¼ í‘œì‹œí•˜ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”. ì½”ë“œ ì…€ì„ **ë‹¤ì‹œ
    ì‹¤í–‰**í•˜ê³  ê²°ê³¼ë¥¼ ë³´ì„¸ìš”. ê·¸ë¦¼ì—ëŠ” ì½”ë“œì— ì§€ì •ëœ ì„œë¸Œí”Œë¡¯ì´ í¬í•¨ë˜ì–´
    ìˆìŠµë‹ˆë‹¤.

> CodeCopy
>
> from matplotlib import pyplot as plt
>
> \# Clear the plot area
>
> plt.clf()
>
> \# Create a figure for 2 subplots (1 row, 2 columns)
>
> fig, ax = plt.subplots(1, 2, figsize = (10,4))
>
> \# Create a bar plot of revenue by year on the first axis
>
> ax\[0\].bar(x=df_sales\['OrderYear'\],
> height=df_sales\['GrossRevenue'\], color='orange')
>
> ax\[0\].set_title('Revenue by Year')
>
> \# Create a pie chart of yearly order counts on the second axis
>
> yearly_counts = df_sales\['OrderYear'\].value_counts()
>
> ax\[1\].pie(yearly_counts)
>
> ax\[1\].set_title('Orders per Year')
>
> ax\[1\].legend(yearly_counts.keys().tolist())
>
> \# Add a title to the Figure
>
> fig.suptitle('Sales Data')
>
> \# Show the figure
>
> plt.show()
>
> ![A screenshot of a computer program AI-generated content may be
> incorrect.](./media/image87.png)
>
> ![A screenshot of a computer screen AI-generated content may be
> incorrect.](./media/image88.png)

**ì°¸ê³ :** matplotlibë¥¼ ì‚¬ìš©í•œ í”Œë¡œíŒ…ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€[*matplotlib
documentation*](https://matplotlib.org/)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ì‘ì—… 3: seaborn ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©

**matplotlib**ë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ ìœ í˜•ì˜ ë³µì¡í•œ ì°¨íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì§€ë§Œ
ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ë³µì¡í•œ ì½”ë“œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ
ìˆ˜ë…„ì— ê±¸ì³ ë³µì¡ì„±ì„ ì¶”ìƒí™”í•˜ê³  ê¸°ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ matplotlibë¥¼
ê¸°ë°˜ìœ¼ë¡œ ë§ì€ ìƒˆë¡œìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬í•œ ë„ì„œê´€ ì¤‘
í•˜ë‚˜ê°€ **Seaborn**ì…ë‹ˆë‹¤.

1.  \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.

CodeCopy

> import seaborn as sns
>
> \# Clear the plot area
>
> plt.clf()
>
> \# Create a bar chart
>
> ax = sns.barplot(x="OrderYear", y="GrossRevenue", data=df_sales)
>
> plt.show()

2.  **ì½”ë“œë¥¼ ì‹¤í–‰**í•˜ê³  seaborn ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§‰ëŒ€ ì°¨íŠ¸ê°€
    í‘œì‹œë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image89.png)

3.  ë‹¤ìŒê³¼ ê°™ì´ ì½”ë“œë¥¼ **ìˆ˜ì •í•˜ì„¸ìš”**. ìˆ˜ì •ëœ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  seabornì„
    ì‚¬ìš©í•˜ë©´ í”Œë¡¯ì— ëŒ€í•´ ì¼ê´€ëœ ìƒ‰ìƒ í…Œë§ˆë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> CodeCopy
>
> import seaborn as sns
>
> \# Clear the plot area
>
> plt.clf()
>
> \# Set the visual theme for seaborn
>
> sns.set_theme(style="whitegrid")
>
> \# Create a bar chart
>
> ax = sns.barplot(x="OrderYear", y="GrossRevenue", data=df_sales)
>
> plt.show()
>
> ![A screenshot of a graph AI-generated content may be
> incorrect.](./media/image90.png)

4.  ì½”ë“œë¥¼ ë‹¤ì‹œ **ìˆ˜ì •í•˜ì„¸ìš”**. ìˆ˜ì •ëœ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì—°ê°„ ìˆ˜ìµì„
    êº¾ì€ì„ í˜• ì°¨íŠ¸ë¡œ ë´…ë‹ˆë‹¤.

> CodeCopy
>
> import seaborn as sns
>
> \# Clear the plot area
>
> plt.clf()
>
> \# Create a bar chart
>
> ax = sns.lineplot(x="OrderYear", y="GrossRevenue", data=df_sales)
>
> plt.show()
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image91.png)

**ì°¸ê³ :** seabornì„ ì‚¬ìš©í•œ í”Œë¡œíŒ…ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€[*seaborn
documentation*](https://seaborn.pydata.org/index.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ì‘ì—… 4: ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ì— Delta table ì‚¬ìš©

Delta LakeëŠ” ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. Delta tableì€ Spark êµ¬ì¡°ì 
ìŠ¤íŠ¸ë¦¬ë° APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë§Œë“  ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì˜ ì‹±í¬ ë˜ëŠ” ì›ë³¸ì¼ ìˆ˜
ìˆìŠµë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ëœ IoT(ì‚¬ë¬¼ ì¸í„°ë„·) ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¼ë¶€
ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì— ëŒ€í•œ ì‹±í¬ë¡œ Delta tableì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

1.  \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì€ í›„ **Run cell**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

CodeCopy

> from notebookutils import mssparkutils
>
> from pyspark.sql.types import \*
>
> from pyspark.sql.functions import \*
>
> \# Create a folder
>
> inputPath = 'Files/data/'
>
> mssparkutils.fs.mkdirs(inputPath)
>
> \# Create a stream that reads data from the folder, using a JSON
> schema
>
> jsonSchema = StructType(\[
>
> StructField("device", StringType(), False),
>
> StructField("status", StringType(), False)
>
> \])
>
> iotstream =
> spark.readStream.schema(jsonSchema).option("maxFilesPerTrigger",
> 1).json(inputPath)
>
> \# Write some event data to the folder
>
> device_data = '''{"device":"Dev1","status":"ok"}
>
> {"device":"Dev1","status":"ok"}
>
> {"device":"Dev1","status":"ok"}
>
> {"device":"Dev2","status":"error"}
>
> {"device":"Dev1","status":"ok"}
>
> {"device":"Dev1","status":"error"}
>
> {"device":"Dev2","status":"ok"}
>
> {"device":"Dev2","status":"error"}
>
> {"device":"Dev1","status":"ok"}'''
>
> mssparkutils.fs.put(inputPath + "data.txt", device_data, True)
>
> print("Source stream created...")
>
> ![A screenshot of a computer program AI-generated content may be
> incorrect.](./media/image92.png)
>
> ![A screenshot of a computer program AI-generated content may be
> incorrect.](./media/image93.png)

2.  ***Â Source stream created...*** ì¸ì‡„ë©ë‹ˆë‹¤. ë°©ê¸ˆ ì‹¤í–‰í•œ ì½”ë“œëŠ” ì¼ë¶€
    ë°ì´í„°ê°€ ì €ì¥ëœ í´ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì›ë³¸ì„ ë§Œë“¤ì–´ ê°€ìƒì˜
    IoT ë””ë°”ì´ìŠ¤ì˜ íŒë…ê°’ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

3.  \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì€ í›„ **Run cell**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

CodeCopy

> \# Write the stream to a delta table
>
> delta_stream_table_path = 'Tables/iotdevicedata'
>
> checkpointpath = 'Files/delta/checkpoint'
>
> deltastream =
> iotstream.writeStream.format("delta").option("checkpointLocation",
> checkpointpath).start(delta_stream_table_path)
>
> print("Streaming to delta sink...")
>
> ![](./media/image94.png)

4.  ì´ ì½”ë“œëŠ” Delta í˜•ì‹ì˜ ìŠ¤íŠ¸ë¦¬ë° ë””ë°”ì´ìŠ¤ ë°ì´í„°ë¥¼
    **iotdevicedata**ë¼ëŠ” í´ë”ì— ì”ë‹ˆë‹¤. í´ë” ìœ„ì¹˜ì˜ ê²½ë¡œëŠ”
    **Tables**Â í´ë”ì— ìˆìœ¼ë¯€ë¡œ í…Œì´ë¸”ì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤. í…Œì´ë¸” ì˜†ì—
    ìˆëŠ” ê°€ë¡œ ì¤„ì„í‘œë¥¼ í´ë¦­í•œ í›„ **Refresh**ì„ í´ë¦­í•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image95.png)

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image96.png)

5.  \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì€ í›„ **Run cell**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

> SqlCopy
>
> %%sql
>
> SELECT \* FROM IotDeviceData;
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image97.png)

6.  ì´ ì½”ë“œëŠ” ìŠ¤íŠ¸ë¦¬ë° ì›ë³¸ì˜ ë””ë°”ì´ìŠ¤ ë°ì´í„°ê°€ í¬í•¨ëœ **IotDeviceData**
    í…Œì´ë¸”ì„ ì¿¼ë¦¬í•˜ì„¸ìš”.

7.  \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì€ í›„ **Run cell**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

> CodeCopy
>
> \# Add more data to the source stream
>
> more_data = '''{"device":"Dev1","status":"ok"}
>
> {"device":"Dev1","status":"ok"}
>
> {"device":"Dev1","status":"ok"}
>
> {"device":"Dev1","status":"ok"}
>
> {"device":"Dev1","status":"error"}
>
> {"device":"Dev2","status":"error"}
>
> {"device":"Dev1","status":"ok"}'''
>
> mssparkutils.fs.put(inputPath + "more-data.txt", more_data, True)
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image98.png)

8.  This code writes more hypothetical device data to the streaming
    source.

9.  \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì€ í›„ **Run cell**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

> SqlCopy
>
> %%sql
>
> SELECT \* FROM IotDeviceData;
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image99.png)

10. ì´ ì½”ë“œëŠ” **IotDeviceData** í…Œì´ë¸”ì„ ë‹¤ì‹œ ì¿¼ë¦¬í•˜ë©°, ì´ì œ ìŠ¤íŠ¸ë¦¬ë°
    ì›ë³¸ì— ì¶”ê°€ëœ ì¶”ê°€ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

11. \+ **Code**ë¥¼ í´ë¦­í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì€ í›„ **Run cell**
    ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

> CodeCopy
>
> deltastream.stop()
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image100.png)

12. ì´ ì½”ë“œëŠ” ìŠ¤íŠ¸ë¦¼ì„ ì¤‘ì§€í•©ë‹ˆë‹¤..

## ì‘ì—… 5: Notebook ì €ì¥ ë° Spark ì„¸ì…˜ ì¢…ë£Œ

ì´ì œ ë°ì´í„° ì‘ì—…ì„ ë§ˆì³¤ìœ¼ë¯€ë¡œ Notebookì„ ì˜ë¯¸ ìˆëŠ” ì´ë¦„ìœ¼ë¡œ ì €ì¥í•˜ê³ 
Spark ì„¸ì…˜ì„ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1.  ë…¸íŠ¸ë¶ ë©”ë‰´ ëª¨ìŒì—ì„œ **âš™ï¸ Settings**Â ì•„ì´ì½˜ì„ ì‚¬ìš©í•˜ì—¬ ë…¸íŠ¸ë¶ ì„¤ì •ì„
    ë³´ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image101.png)

2.  Notebookì˜ **Name**ì„ +++**Explore Sales Orders**+++ë¡œ ì„¤ì •í•œ í›„
    ì„¤ì • ì°½ì„ ë‹«ìœ¼ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image102.png)

3.  Notebook ë©”ë‰´ì—ì„œ **Stop sessionë¥¼** ì„ íƒí•˜ì—¬ Spark ì„¸ì…˜ì„
    ì¢…ë£Œí•©ë‹ˆë‹¤.

![A screenshot of a computer Description automatically
generated](./media/image103.png)

![A screenshot of a computer Description automatically
generated](./media/image104.png)

# ì—°ìŠµ 5: Microsoft Fabricì—ì„œ Dataflow (Gen2) ìƒì„±í•˜ê¸°

Microsoft Fabricì—ì„œ Dataflow(Gen2)ì€ ë‹¤ì–‘í•œ ë°ì´í„° ì›ë³¸ì— ì—°ê²°í•˜ê³ 
Power Query Onlineì—ì„œ ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë°ì´í„°
íŒŒì´í”„ë¼ì¸ì—ì„œ ë°ì´í„°ë¥¼ Lakehouse ë˜ëŠ” ê¸°íƒ€ ë¶„ì„ ì €ì¥ì†Œë¡œ ìˆ˜ì§‘í•˜ê±°ë‚˜
Power BI ë³´ê³ ì„œì— ëŒ€í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì •ì˜í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ì—°ìŠµì€ Dataflow(Gen2)ì˜ ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ì†Œê°œí•˜ê³  ì—”í„°í”„ë¼ì´ì¦ˆì— ì¡´ì¬í• 
ìˆ˜ ìˆëŠ” ë³µì¡í•œ ì†”ë£¨ì…˜ì„ ë§Œë“¤ì§€ ì•Šë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤

## ì‘ì—… 1: ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ Dataflow(Gen2) ìƒì„±í•˜ê¸°

ì´ì œ Lakehouseê°€ ìˆìœ¼ë¯€ë¡œ ì¼ë¶€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìˆ˜í–‰í•˜ëŠ”
í•œ ê°€ì§€ ë°©ë²•ì€ *extract, transform, and loadÂ (ETL)* í”„ë¡œì„¸ìŠ¤ë¥¼
ìº¡ìŠí™”í•˜ëŠ” Dataflowì„ ì •ì˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

1.  ì´ì œ ì™¼ìª½ íƒìƒ‰ ì°½ì—ì„œ **Fabric_lakehouse**ë¥¼ í´ë¦­í•˜ì„¸ìš”.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image105.png)

2.  **Fabric_lakehouse** í™ˆí˜ì´ì§€ì—ì„œ **Get data**ì˜ ë“œë¡­ë‹¤ìš´ í™”ì‚´í‘œë¥¼
    í´ë¦­í•˜ê³  **New Dataflow Gen2ë¥¼** ì„ íƒí•˜ì„¸ìš”. ìƒˆ Dataflowì— ëŒ€í•œ
    Power Query í¸ì§‘ê¸°ê°€ ì—´ë¦½ë‹ˆë‹¤.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image106.png)

5.  **New Dataflow Gen2** ëŒ€í™” ìƒìì˜ **NameÂ **í•„ë“œì—
    +++**Gen2_Dataflow**+++ë¥¼ ì…ë ¥í•˜ê³  Create ë²„íŠ¼ì„ í´ë¦­í•œ í›„ ìƒˆ
    Dataflow Gen2ë¥¼ ì—¬ì„¸ìš”.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image107.png)

3.  **Home tab**ì˜ **Power Query** ì°½ì—ì„œ **Import from a Text/CSV
    file**ì„ í´ë¦­í•˜ì„¸ìš”.

> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image108.png)

4.  **Connect to data source** ì°½ì— **Connection settings**ì—ì„œ **Link
    to file (Preview)** ë¼ë””ì˜¤ ë²„íŠ¼ì„ ì„ íƒí•˜ì„¸ìš”

- **Link to file**:Â *Selected*

- **File path or
  URL**:Â +++https://raw.githubusercontent.com/MicrosoftLearning/dp-data/main/orders.csv+++

![](./media/image109.png)

5.  **Connect to data source** ì°½ì— **Connection credentials**ì—ì„œ ë‹¤ìŒ
    ì„¸ë¶€ ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  **Next** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

- **Connection**: Create new connection

- **data gateway**: (none)

- **Authentication kind**: Anonymous

> ![](./media/image110.png)

6.  **Preview file data** ì°½ì—ì„œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ìƒì„±í•˜ë ¤ë©´ **Create**ë¥¼
    í´ë¦­í•˜ì„¸ìš”. ![A screenshot of a computer Description automatically
    generated](./media/image111.png)

7.  **Power Query**í¸ì§‘ê¸°ì—ëŠ” ë°ì´í„° ì›ë³¸ê³¼ ë°ì´í„° ì„œì‹ì„ ì§€ì •í•˜ê¸° ìœ„í•œ
    ì´ˆê¸° ì¿¼ë¦¬ ë‹¨ê³„ ì§‘í•©ì´ í‘œì‹œë©ë‹ˆë‹¤.

![A screenshot of a computer Description automatically
generated](./media/image112.png)

8.  toolbar ribbonì—ì„œ, select theÂ **Add column**Â íƒ­ì„ ì„ íƒí•˜ì„¸ìš”.
    **Custom column**ì„ ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image113.png)Â 

9.  ìƒˆ ì—´ ì´ë¦„ì„ +++ **MonthNo** +++ë¡œ ì„¤ì •í•˜ê³ , ë°ì´í„° í˜•ì‹ì„ **Whole
    Number**ë¡œ ì„¤ì •í•œ í›„, **Custom column formula** ìˆ˜ì‹ì— ë‹¤ìŒ ìˆ˜ì‹ì„
    ì¶”ê°€í•˜ì„¸ìš”:+++ **Date.Month(\[OrderDate\])+++** í™•ì¸ì„ ì„ íƒí•˜ì„¸ìš”.
    **OK**ë¥¼ ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image114.png)

10. ì‚¬ìš©ì ì§€ì • ì—´ì„ ì¶”ê°€í•˜ëŠ” ë‹¨ê³„ê°€ ì¿¼ë¦¬ì— ì–´ë–»ê²Œ ì¶”ê°€ë˜ëŠ”ì§€
    í™•ì¸í•©ë‹ˆë‹¤. ê²°ê³¼ ì—´ì´ ë°ì´í„° ì°½ì— í‘œì‹œë©ë‹ˆë‹¤.

![A screenshot of a computer Description automatically
generated](./media/image115.png)

**íŒ:** ì˜¤ë¥¸ìª½ì˜ ì¿¼ë¦¬ ì„¤ì • ì°½ì—ì„œ **ì ìš©ëœ ë‹¨ê³„**ì— ê° ë³€í™˜ ë‹¨ê³„ê°€
í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•˜ë‹¨ì—ì„œ **ë‹¤ì´ì–´ê·¸ë¨ íë¦„** ë²„íŠ¼ì„ ì „í™˜í•˜ì—¬ ë‹¨ê³„ì˜
ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨ì„ ì¼¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

ë‹¨ê³„ë¥¼ ìœ„ ë˜ëŠ” ì•„ë˜ë¡œ ì´ë™í•˜ê³ , í†±ë‹ˆë°”í€´ ì•„ì´ì½˜ì„ ì„ íƒí•˜ì—¬ í¸ì§‘í•  ìˆ˜
ìˆìœ¼ë©°, ê° ë‹¨ê³„ë¥¼ ì„ íƒí•˜ì—¬ ë¯¸ë¦¬ë³´ê¸° ì°½ì—ì„œ ë³€í™˜ì´ ì ìš©ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜
ìˆìŠµë‹ˆë‹¤.

ì‘ì—… 2: Dataflowì— ëŒ€í•œ ë°ì´í„° ëŒ€ìƒ ì¶”ê°€

1.  **Power Query** toolbar ribbonì—ì„œ **Home**Â íƒ­ì„ ì„ íƒí•˜ì„¸ìš”. D**ata
    destination**Â ë“œë¡­ë‹¤ìš´ ë©”ë‰´ì—ì„œ **Lakehouse**ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì„ íƒë˜ì§€
    ì•ŠëŠ” ê²½ìš°).

![](./media/image116.png)

![A screenshot of a computer Description automatically
generated](./media/image117.png)

**ì°¸ê³ :** ì´ ì˜µì…˜ì´ íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œë˜ë©´ ì´ë¯¸ ë°ì´í„° ëŒ€ìƒì´ ì„¤ì •ë˜ì–´ ìˆì„
ìˆ˜ ìˆìŠµë‹ˆë‹¤. Power Query í¸ì§‘ê¸°ì˜ ì˜¤ë¥¸ìª½ì— ìˆëŠ” ì¿¼ë¦¬ ì„¤ì • ì°½ ì•„ë˜ìª½ì—ì„œ
ë°ì´í„° ëŒ€ìƒì„ í™•ì¸í•©ë‹ˆë‹¤. ëª©ì ì§€ê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆëŠ” ê²½ìš° ê¸°ì–´ë¥¼
ì‚¬ìš©í•˜ì—¬ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

2.  **Lakehouse**Â ëŒ€ìƒì€ Power Query í¸ì§‘ê¸°ì˜ **query**ì— **icon**ìœ¼ë¡œ
    í‘œì‹œë©ë‹ˆë‹¤.

![A screenshot of a computer Description automatically
generated](./media/image118.png)

![A screenshot of a computer Description automatically
generated](./media/image119.png)

3.  dataflowë¥¼ ê²Œì‹œí•˜ë ¤ë©´ **Publish**ë¥¼ ì„ íƒí•˜ì„¸ìš”. ì‘ì—… ì˜ì—­ì—ì„œ
    **Dataflow** 1 Dataflowì´ ë§Œë“¤ì–´ì§ˆ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image120.png)

![](./media/image121.png)

## ì‘ì—… 3: íŒŒì´í”„ë¼ì¸ì— Dataflow ì¶”ê°€

Dataflowì„ íŒŒì´í”„ë¼ì¸ì˜ í™œë™ìœ¼ë¡œ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì€ ë°ì´í„°
ìˆ˜ì§‘ ë° ì²˜ë¦¬ í™œë™ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì´ë¥¼ í†µí•´ Dataflowì„
ì˜ˆì•½ëœ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ì—ì„œ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ì‘ì—…ê³¼ ê²°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
íŒŒì´í”„ë¼ì¸ì€ Data Factory í™˜ê²½ì„ í¬í•¨í•˜ì—¬ ëª‡ ê°€ì§€ ë‹¤ë¥¸ í™˜ê²½ì—ì„œ ë§Œë“¤ ìˆ˜
ìˆìŠµë‹ˆë‹¤.

1.  Synapse Data Engineering í™ˆí˜ì´ì§€ì˜ **dp_FabricXX** ì°½ì—ì„œ **+New
    item** -\> **Data pipeline**ë¥¼ ì„ íƒí•˜ì„¸ìš”

![](./media/image122.png)

2.  **New pipeline**Â ëŒ€í™” ìƒìì—ì„œ **Name**Â í•„ë“œì— **Load data**ë¥¼
    ì…ë ¥í•˜ê³  ìƒˆ íŒŒì´í”„ë¼ì¸ì„ ì—´ë ¤ë©´ **Create** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image123.png)

3.  íŒŒì´í”„ë¼ì¸ í¸ì§‘ê¸°ê°€ ì—´ë¦½ë‹ˆë‹¤.

![A screenshot of a computer Description automatically
generated](./media/image124.png)

> **íŒ**: ë°ì´í„° ë³µì‚¬ ë§ˆë²•ì‚¬ê°€ ìë™ìœ¼ë¡œ ì—´ë¦¬ë©´ ë‹«ìœ¼ì‹­ì‹œì˜¤!

4.  **Pipeline activity**ë¥¼ ì„ íƒí•˜ê³  íŒŒì´í”„ë¼ì¸ì—Â **Dataflow**Â í™œë™ì„
    ì¶”ê°€í•˜ì„¸ìš”.

![](./media/image125.png)

5.  ìƒˆ **Dataflow1** í™œë™ì„ ì„ íƒí•œ ìƒíƒœì—ì„œ **SettingsÂ **íƒ­ì˜
    **DataflowÂ **ë“œë¡­ë‹¤ìš´ ëª©ë¡ì—ì„œ **Gen2_Dataflow**(ì´ì „ì— ë§Œë“ 
    Dataflow)ë¥¼ ì„ íƒí•˜ì„¸ìš”

![](./media/image126.png)

6.  **Home**Â íƒ­ì—ì„œÂ **ğŸ–«Â (*Save*)** ì•„ì´ì½˜ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„
    ì €ì¥í•˜ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image127.png)

7.  â–· **RunÂ **ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³  ì™„ë£Œë  ë•Œê¹Œì§€
    ê¸°ë‹¤ë¦¬ì„¸ìš”. ëª‡ ë¶„ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ![A screenshot of a computer Description automatically
> generated](./media/image128.png)
>
> ![A screenshot of a computer AI-generated content may be
> incorrect.](./media/image129.png)

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image130.png)

8.  ì™¼ìª½ ê°€ì¥ìë¦¬ì˜ ë©”ë‰´ ëª¨ìŒì—ì„œ ì‘ì—… ê³µê°„(ì˜ˆ: **dp_FabricXX**ë¥¼
    ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image131.png)

![A screenshot of a computer Description automatically
generated](./media/image132.png)

9.  **Fabric_lakehouse** ì°½ì—ì„œ Lakehouse ìœ í˜•ì˜
    **Gen2_FabricLakehouse**ë¥¼ ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer AI-generated content may be
incorrect.](./media/image133.png)

![A screenshot of a computer Description automatically
generated](./media/image134.png)

10. **Explorer**ì°½ì—ì„œ ...Â **Tables**ì˜ ë©”ë‰´ì—ì„œ **refresh**ì„
    ì„ íƒí•˜ì„¸ìš”. **Tables**Â ì„ í™•ì¥í•˜ê³  Dataflowì—ì„œ ìƒì„±í•œ
    **orders**Â í…Œì´ë¸”ì„ ì„ íƒí•˜ì„¸ìš”.

![A screenshot of a computer Description automatically
generated](./media/image135.png)

![](./media/image136.png)

**íŒ**: Power BI Desktop *Dataflow ì»¤ë„¥í„°*ë¥¼ ì‚¬ìš©í•˜ì—¬ Dataflowìœ¼ë¡œ
ìˆ˜í–‰ëœ ë°ì´í„° ë³€í™˜ì— ì§ì ‘ ì—°ê²°í•©ë‹ˆë‹¤.

ë˜í•œ ì¶”ê°€ ë³€í™˜ì„ ìˆ˜í–‰í•˜ê³ , ìƒˆ ë°ì´í„° ì„¸íŠ¸ë¡œ ê²Œì‹œí•˜ê³ , íŠ¹ìˆ˜ ë°ì´í„° ì„¸íŠ¸ì—
ëŒ€í•´ ì˜ë„í•œ ëŒ€ìƒê³¼ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## íƒœìŠ¤í¬ 4: ë¦¬ì†ŒìŠ¤ ì •ë¦¬í•˜ê¸°

ì´ ì—°ìŠµì—ì„œëŠ” Sparkë¥¼ ì‚¬ìš©í•˜ì—¬ Microsoft Fabricì—ì„œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ”
ë°©ë²•ì„ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤.

Lakehouse íƒìƒ‰ì„ ë§ˆì¹œ ê²½ìš° ì´ ì—°ìŠµì„ ìœ„í•´ ë§Œë“  ì‘ì—… ì˜ì—­ì„ ì‚­ì œí•  ìˆ˜
ìˆìŠµë‹ˆë‹¤.

1.  ì™¼ìª½ ë§‰ëŒ€ì—ì„œ ì‘ì—… ì˜ì—­ì˜ ì•„ì´ì½˜ì„ ì„ íƒí•˜ì—¬ í¬í•¨ëœ ëª¨ë“  í•­ëª©ì„
    ë´…ë‹ˆë‹¤.

> ![A screenshot of a computer Description automatically
> generated](./media/image137.png)

2.  ë©”ë‰´ì—ì„œ **...**ë¥¼ í´ë¦­í•˜ê³  **Workspace settings**ì„ ì„ íƒí•˜ì„¸ìš”.

![](./media/image138.png)

3.  **General**ì„ ì„ íƒí•˜ê³  **Remove this workspace**ë¥¼ ì„ íƒí•˜ì„¸ìš”**.**

![A screenshot of a computer settings Description automatically
generated](./media/image139.png)

4.  **Delete workspace?** ëŒ€í™” ìƒìì—ì„œ **Delete** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

> ![A screenshot of a computer Description automatically
> generated](./media/image140.png)
>
> ![A screenshot of a computer Description automatically
> generated](./media/image141.png)

**ìš”ì•½**

ì´ ì‚¬ìš© ì‚¬ë¡€ëŠ” Power BI ë‚´ì—ì„œ Microsoft Fabricì„ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼
ì•ˆë‚´í•©ë‹ˆë‹¤. ì‘ì—… ê³µê°„ ì„¤ì •, Lakehouse ìƒì„±, ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ ë° ê´€ë¦¬,
ë°ì´í„° íƒìƒ‰ì„ ìœ„í•œ ë…¸íŠ¸ë¶ ì‚¬ìš© ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì°¸ê°€ìëŠ”
PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì¡°ì‘ ë° ë³€í™˜í•˜ê³ , ì‹œê°í™”ë¥¼ ìƒì„±í•˜ê³ ,
íš¨ìœ¨ì ì¸ ì¿¼ë¦¬ë¥¼ ìœ„í•´ ë°ì´í„°ë¥¼ ì €ì¥ ë° ë¶„í• í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.

ì´ ì‚¬ìš© ì‚¬ë¡€ì—ì„œ ì°¸ê°€ìëŠ” Microsoft Fabricì˜ Delta table ì‘ì—…ì— ì¤‘ì ì„
ë‘” ì¼ë ¨ì˜ ì‘ì—…ì— ì°¸ì—¬í•©ë‹ˆë‹¤. ì‘ì—…ì—ëŠ” ë°ì´í„° ì—…ë¡œë“œ ë° íƒìƒ‰, ê´€ë¦¬í˜• ë°
ì™¸ë¶€ Delta table ìƒì„±, ì†ì„± ë¹„êµ, êµ¬ì¡°í™”ëœ ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•œ SQL ê¸°ëŠ¥
ë„ì…, matplotlib ë° seabornê³¼ ê°™ì€ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ë°ì´í„°
ì‹œê°í™”ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•˜ëŠ” ì‘ì—…ì´ í¬í•¨ë©ë‹ˆë‹¤. ì´ ì—°ìŠµì€ ë°ì´í„°
ë¶„ì„ì— Microsoft Fabricì„ í™œìš©í•˜ê³  IoT ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ì„
ìœ„í•œ Delta tableì„ í†µí•©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ í¬ê´„ì ì¸ ì´í•´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì„
ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

ì´ ì‚¬ìš© ì‚¬ë¡€ëŠ” Fabric ì‘ì—… ì˜ì—­ì„ ì„¤ì •í•˜ê³ , Data Lakehouseë¥¼ ë§Œë“¤ê³ ,
ë¶„ì„ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤. ETL ì‘ì—…ì„ ì²˜ë¦¬í•˜ê¸°
ìœ„í•´ Dataflowì„ ì •ì˜í•˜ê³  ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ë°ì´í„° ëŒ€ìƒì„
êµ¬ì„±í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ ìë™í™”ëœ ì²˜ë¦¬ë¥¼ ìœ„í•´ Dataflowì„
íŒŒì´í”„ë¼ì¸ì— í†µí•©í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì—°ìŠµì´ ì™„ë£Œë˜ë©´
ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ëŠ” ì§€ì¹¨ì´ ì œê³µë©ë‹ˆë‹¤.

ì´ ë©ì—ì„œëŠ” Fabric ì‘ì—…ì— í•„ìš”í•œ í•„ìˆ˜ ê¸°ìˆ ì„ ì œê³µí•˜ì—¬ ì‘ì—… ì˜ì—­ì„ ë§Œë“¤ê³ 
ê´€ë¦¬í•˜ê³ , Data Lakehouseë¥¼ ì„¤ì •í•˜ê³ , ë°ì´í„° ë³€í™˜ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜
ìˆë„ë¡ í•©ë‹ˆë‹¤. Dataflowì„ íŒŒì´í”„ë¼ì¸ì— í†µí•©í•˜ë©´ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì„
ìë™í™”í•˜ê³  ì‘ì—… íë¦„ì„ ê°„ì†Œí™”í•˜ë©° ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìƒì‚°ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ”
ë°©ë²•ì„ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤. ì •ë¦¬ ì§€ì¹¨ì„ í†µí•´ ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ë‚¨ê¸°ì§€ ì•Šê³ 
ì²´ê³„ì ì´ê³  íš¨ìœ¨ì ì¸ ì‘ì—… ê³µê°„ ê´€ë¦¬ ì ‘ê·¼ ë°©ì‹ì„ ì´‰ì§„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
